{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export notebook as python script to the ../python-code - folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(\"jupyter nbcbonvert --output-dir='../python-code' --to python Naive_Bayes.ipynb --TemplateExporter.exclude_markdown=True --TemplateExporter.exclude_input_prompt=True\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Naive_Bayes_CF():\n",
    "    \"\"\"\n",
    "    Class representing a Naive - Bayes classifier implementation for the collaborative filterting setting of recommender systems.\n",
    "    \"\"\"\n",
    "    def __init__(self, rmh, is_task_conviction:bool=True):\n",
    "        super().__init__()\n",
    "        self.rmh_ = rmh\n",
    "        self.is_task_conviction = is_task_conviction\n",
    "        if is_task_conviction:\n",
    "            self.possibles_classes = set([0,1])\n",
    "            self.test_eval_indices = {user:items[items % 2 == 1] for user,items in self.rmh_.test_eval_indices.items()}\n",
    "        else:\n",
    "            self.possibles_classes = set([i for i in range(7)])\n",
    "            self.test_eval_indices = {user:items[items % 2 == 0] for user,items in self.rmh_.test_eval_indices.items()}\n",
    "            \n",
    "        self.numerical_rating_matrix = self.rmh_.final_rating_matrix_w_usernames.drop(\"username\", axis=1).values\n",
    "    \n",
    "    def build_lookups(self) -> None:\n",
    "        \"\"\"\n",
    "        Map users and items to numerical values for further indexing.\n",
    "        \"\"\"\n",
    "        self.userid_lookup_ = {username: i for i, username in enumerate(self.rmh_.final_rating_matrix_w_usernames[\"username\"])}\n",
    "        self.itemid_lookup_ = {item: i-1 for i, item in enumerate(list(self.rmh_.final_rating_matrix_w_usernames.columns))}\n",
    "        # Reverse the two calculated mappings for bidirectional lookup\n",
    "        self.username_lookup = {user_id: username for username, user_id in self.userid_lookup_.items()}\n",
    "        self.itemname_lookup = {item_id: itemname for itemname, item_id in self.itemid_lookup_.items()}\n",
    "    \n",
    "    def compute_prior_prob(self) -> None:\n",
    "        \"\"\"\n",
    "        Compute the prior probability for every item/rating combination and save it into a class dictionary.\n",
    "        \"\"\"\n",
    "        items_without_username = set([self.itemid_lookup_[item] for item in self.itemid_lookup_.keys() if item != \"username\"])\n",
    "        # Build dictionary to hold the prior probabilities for all item/class combinations\n",
    "        self.prior_prob_for_item = {item_id: {} for item_id in items_without_username}\n",
    "        for item_id in items_without_username:\n",
    "            for c in self.possibles_classes:\n",
    "                # Calculate the number of users that rated the item with class c\n",
    "                class_count = len(self.numerical_rating_matrix[self.numerical_rating_matrix[:,item_id] == c])\n",
    "                # Calculate all the users that gave a rating for the item\n",
    "                rated_count = np.sum(~np.isnan(self.numerical_rating_matrix[:,item_id]))\n",
    "                self.prior_prob_for_item[item_id][c] = class_count / rated_count\n",
    "    \n",
    "    def compute_users_that_rated_item_with_class(self) -> None:\n",
    "        \"\"\"\n",
    "        Compute a lookup dictionary that associates a item-id with all possibles classes. \n",
    "        These classes itself are associated with all users that rated the associated item with the associated class.\n",
    "        \"\"\"\n",
    "        items_without_username = set([self.itemid_lookup_[item] for item in self.itemid_lookup_.keys() if item != \"username\"])\n",
    "        self.users_rated_item_with_class = {i: {c: None} for c in self.possibles_classes for i in items_without_username}\n",
    "        \n",
    "        for item_id in items_without_username:\n",
    "            for c in self.possibles_classes:\n",
    "                # Calculate the users that rated the item with the class\n",
    "                users = np.argwhere(self.numerical_rating_matrix[:,item_id] == c).flatten()\n",
    "                # Set the users in the dictionary\n",
    "                self.users_rated_item_with_class[item_id][c] = users\n",
    "                  \n",
    "    def compute_likelihood(self, _class:int, item:int, user:int) -> float:\n",
    "        \"\"\"\n",
    "        Compute the likelihood of observed ratings given the class for a provided user-item combination.\n",
    "        \n",
    "        Returns:\n",
    "            float: The computed likelihood.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute items the user has rated\n",
    "        items_rated_by_user = np.argwhere(~np.isnan(self.numerical_rating_matrix[user]))\n",
    "        \n",
    "        # Get users that rated the provided item with the provided class\n",
    "        users_rated_item_with_class = self.users_rated_item_with_class[item][_class]\n",
    "        \n",
    "        likelihood = 1\n",
    "        for k in items_rated_by_user:\n",
    "            # The rating r_u_k given by the provided user to item k\n",
    "            rating_given_by_user = self.numerical_rating_matrix[user][k]\n",
    "            # The number of users that rated the provided item with the provided class and that additionaly rated item k with r_u_k\n",
    "            num_users_identical_rating = np.sum(self.numerical_rating_matrix[[users_rated_item_with_class]][:,k] == rating_given_by_user)\n",
    "            # The number of users that rated the provided item with the provided class and specified a rating for item k\n",
    "            all_users = len(self.numerical_rating_matrix[[users_rated_item_with_class]][:,k])\n",
    "            # Due to assumption of independence of ratings, the likelihood is the result of a product of the single probalities\n",
    "            likelihood *= (num_users_identical_rating / all_users)\n",
    "            \n",
    "        return likelihood\n",
    "    \n",
    "    def predict(self, user:int, item:int) -> int:\n",
    "        \"\"\"\n",
    "        Calculate the most probable class label given the ratings.\n",
    "\n",
    "        Params:\n",
    "            user (int): The user-id for which the prediction is made.\n",
    "            item (int): The item-id for which the prediction is made.\n",
    "\n",
    "        Returns:\n",
    "            int: The class label that maximizes the posterior probability.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get the prior probability for each possible class - label\n",
    "        prior_probs = {c: self.prior_prob_for_item[item][c] for c in self.possibles_classes}\n",
    "        # Variable for holding the posterior probability associated with each class label\n",
    "        posterior_probs = {c: None for c in self.possibles_classes}\n",
    "        # Calculate the posterior probability for all possible class labels\n",
    "        for c in self.possibles_classes:\n",
    "            posterior_probs[c] = self.compute_likelihood(c, item, user) * prior_probs[item][c]\n",
    "        # Return the class label that maximizes the posterior probability\n",
    "        return max(posterior_probs, key=posterior_probs.get)\n",
    "    \n",
    "    def evaluate(self) -> float:\n",
    "        \"\"\"\n",
    "        Calculate the performance score of the Naive Bayes model on the test dataset.\n",
    "\n",
    "        Returns:\n",
    "            float: The performance score on the test dataset. In the case of the 'Conviction' task it is the mean - accuracy error. In the case of the 'Weight' task it is the RMSE.\n",
    "        \"\"\"\n",
    "        # Only retrieve the test instances of the conviction task (odd-indexed)\n",
    "        if self.is_task_conviction:\n",
    "            # Calculate the mean-accuracy for the Prediction of Conviction (PoC) - task \n",
    "            mean_acc = 0.0\n",
    "            # Variable for counting the correct 0/1 prediction\n",
    "            count_equality = 0\n",
    "            for username, test_samples in self.test_eval_indices.items():\n",
    "                # Get the target-user id\n",
    "                target_user_id = self.userid_lookup_[username[0]]\n",
    "                for item_id in test_samples:\n",
    "                # Look up the true value \n",
    "                    true_value = self.rmh_task_test_rating_matrix[self.task_test_rating_matrix[\"username\"] == username[0]][self.itemname_lookup_[item_id//2]]\n",
    "                    prediction = round(self.predict(target_user_id, item_id))\n",
    "                    # If the prediction is correct, increment the counter\n",
    "                    if  true_value == prediction:\n",
    "                        count_equality += 1\n",
    "                # Normalize by the number of test samples for this user\n",
    "                mean_acc += count_equality / len(test_samples)\n",
    "                # Set the count equality to 0 for the next user\n",
    "                count_equality = 0\n",
    "            # Normalize the error by the number of users in the test-set\n",
    "            mean_acc /= len(self.test_eval_indices)\n",
    "        \n",
    "            return mean_acc\n",
    "        \n",
    "        # Only retrieve the test instances of the weight task (even-indexed)\n",
    "        else:\n",
    "            test_eval_indices = np.array([idx for idx in self.rmh_.test_eval_indices if idx[1] % 2 == 0])\n",
    "            rmse_error, prediction_distance = 0.0, 0.0\n",
    "            for username, test_samples in test_eval_indices.items():\n",
    "                # Get the target-user-id\n",
    "                target_user_id = self.userid_lookup_[username[0]]\n",
    "                for arg_idx in test_samples:\n",
    "                    # Look up the true value\n",
    "                    true_value = self.task_test_rating_matrix[self.task_test_rating_matrix[\"username\"] == username[0]][self.itemname_lookup_[item_id//2]]\n",
    "                    prediction = round(self.predict(target_user_id, item_id))\n",
    "                    prediction_distance += (true_value - prediction)**2\n",
    "                # Normalize by the number of test samples for this user     \n",
    "                rmse_error += (prediction_distance / len(test_samples))\n",
    "                # Set the prediction distance to 0 for the next user\n",
    "                prediction_distance = 0\n",
    "            # Normalize the prediction_distance by the number of users in the test-set\n",
    "            rmse_error /= len(test_eval_indices)\n",
    "            \n",
    "            return rmse_error\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c4321509887871942225181aea45e229e5aed2157cb28edcc519edea6ae29dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('ba_thesis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
