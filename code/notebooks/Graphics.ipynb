{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from IPython.core.debugger import set_trace\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export notebook as python script to the ../python-code - folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(\"jupyter nbconvert --output-dir='../python-code' --to python Graphics.ipynb --TemplateExporter.exclude_markdown=True --TemplateExporter.exclude_input_prompt=True\", shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create plots for training and test data T1 -> T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.available\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graphics():\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def create_plot(timepoint:str=\"T1_T2\", mode:str=\"train\", is_task_conviction:bool=True, task:str=\"Conviction\", global_distribution:bool=True, size:tuple=(20,20), normalize_values:bool=True, **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        Create plot of rating distribution.\n",
    "\n",
    "        Params:\n",
    "            timepoint (str, optional): The point in time for which the plot is created. Defaults to \"T1_T2\".\n",
    "            mode(str, optional): The mode for which the data should be processed. Can either be \"train\" or \"test\". Defaults to \"train\".\n",
    "            is_task_conviction (bool, optional): Specify for which task the plot is created. If True it is created for conviction task. If False it is created for the weight task. Defaults to True.\n",
    "            global_distribution(bool, optional): If set to True, the overall distribution of values for the timpoint is plotted as a bar plot. If set to False the stacked rating counts for each item is plotted. Defaults to True.\n",
    "            size (tuple, optional): Specify the size of the plot.\n",
    "        \"\"\"\n",
    "        path = f\"../../data/{timepoint}/{mode}.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        df.drop(\"username\", axis=1, inplace=True)\n",
    "        if is_task_conviction:\n",
    "            df = df[[f\"statement_attitude_{i}\" for i in [j for j in range(324,400) if j != 397]]]\n",
    "            value_range = (0,1)\n",
    "        else:\n",
    "            df = df[[f\"argument_rating_{i}\" for i in [j for j in range(324,400) if j != 397]]]\n",
    "            value_range = (0,1,2,3,4,5,6)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "            \n",
    "        if global_distribution:\n",
    "            # Produce bar plots of the overall value distribution\n",
    "            unique_values, counts_values = np.unique(df.values, return_counts=True)\n",
    "            # Exclude last value as it is nan\n",
    "            unique_values = unique_values[:-1].astype(int)\n",
    "            counts_values = counts_values[:-1].astype(int)\n",
    "            plt.bar(unique_values, counts_values, tick_label=unique_values)\n",
    "            if is_task_conviction:\n",
    "                plt.title(f\"Distribution of Conviction Values for {timepoint}\");\n",
    "                plt.xlabel(\"Conviction Rating Values\")\n",
    "            else:\n",
    "                plt.title(f\"Distribution of Weight Values for {timepoint}\")\n",
    "                plt.xlabel(\"Weight Rating Values\")\n",
    "            plt.rcParams[\"figure.figsize\"] = size\n",
    "            plt.ylabel(ylabel=\"# Ratings\");\n",
    "        \n",
    "        else:\n",
    "            # Produce bar plot of the value counts of all items\n",
    "            value_counts = np.array([np.unique(df[c], return_counts=True) for c in df.columns])\n",
    "            arg_ids = [i for i in range(len(df.columns))]\n",
    "            for v in value_counts:\n",
    "                i = 0\n",
    "                for value in value_range:\n",
    "                    if value not in v[0]:\n",
    "                        v[0] = np.insert(v[0], i, float(value)) \n",
    "                        v[1] = np.insert(v[1], i, 0)\n",
    "                    i += 1\n",
    "                i = 0 \n",
    "            # Zip value counts and ids together to filter out the items without ratings\n",
    "            value_counts = list(map(lambda x: (x[0][:-1], x[1][:-1]) if len(x[1]) != len(value_range) else x, value_counts))\n",
    "            zipped = list(zip(arg_ids, value_counts))\n",
    "            # Filter out all items without ratings\n",
    "            zipped = list(filter(lambda x: len(x[1][0]) > 0, zipped))\n",
    "            arg_ids, value_counts = list(zip(*zipped))\n",
    "            # Get only the counts\n",
    "            value_counts = map(lambda x: x[1], value_counts)\n",
    "            if normalize_values:\n",
    "                value_counts =list(map(lambda x: x / sum(x), value_counts))\n",
    "                # Map to percentage\n",
    "                value_counts = list(map(lambda x: x * 100, value_counts))\n",
    "            # Create tuples of counts for specific values for each item\n",
    "            item_value_counts = list(zip(*value_counts))\n",
    "            first_bar = True\n",
    "            summarize = False\n",
    "            if (not is_task_conviction and not global_distribution):\n",
    "                first = np.sum(item_value_counts[0:3], axis=0)\n",
    "                second = np.sum(item_value_counts[3:], axis=0)\n",
    "                item_value_counts = np.array([first, second])\n",
    "                summarize = True\n",
    "            for i in range(len(item_value_counts)):\n",
    "                if first_bar:\n",
    "                    if summarize:\n",
    "                        ax.bar(arg_ids, item_value_counts[i], label=\"0 - 3\")\n",
    "                    else:\n",
    "                        ax.bar(arg_ids, item_value_counts[i], label=str(i))\n",
    "                else:\n",
    "                    bottom = np.array([sum(x) for x in zip(*item_value_counts[:i])])\n",
    "                    if summarize:\n",
    "                        ax.bar(arg_ids, item_value_counts[i], label=\"4 - 6\", bottom=bottom)\n",
    "                    else:\n",
    "                        ax.bar(arg_ids, item_value_counts[i], label=str(i), bottom=bottom)\n",
    "                first_bar = False\n",
    "            plt.rcParams[\"figure.figsize\"] = size\n",
    "            ax.legend(loc=\"upper left\", bbox_to_anchor=(0.71, 1), ncol=2, prop={\"size\":20})\n",
    "            plt.xlabel(\"Argument Index\")\n",
    "            plt.ylabel(\"Percentage of Ratings\")\n",
    "            plt.rcParams[\"font.size\"] = 20\n",
    "            plt.savefig(fname=f\"../../ba_thesis/images/{timepoint}_{mode}_{task}.jpg\")\n",
    "            return plt.figure()\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_Shannon_Entropy(timepoint=\"T1_T2\", mode=\"train\", task=\"conviction\") -> float:\n",
    "        \"\"\"\n",
    "        Compute the Shannon Entropy of a dataset to measure the balance of the distribution of ratings.\n",
    "\n",
    "        Args:\n",
    "            timepoint (str, optional): The timepoint in which the dataset resides. Defaults to \"T1_T2\".\n",
    "            mode (str, optional): The mode of the dataset. Can be either \"train\", \"validation\" or \"test. Defaults to \"train\".\n",
    "            task (str, optional): The task for which the dataset is used. Can be \"conviction\" or \"weight\". Defaults to \"conviction\".\n",
    "        Returns:\n",
    "            float: A measure of balance for the dataset. 0 means no balance and 1 means totally balanced.\n",
    "        \"\"\"\n",
    "        path = f\"../../data/{timepoint}/{mode}.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        # Depending on the task, choose the corresponding columns\n",
    "        if task == \"conviction\":\n",
    "            df = df[[f\"statement_attitude_{i}\" for i in [j for j in range(324,400) if j != 397]]] \n",
    "            # Number of possible discrete rating values in this task\n",
    "            M = 2\n",
    "        else:\n",
    "            df = df[[f\"argument_rating_{i}\" for i in [j for j in range(324,400) if j != 397]]]\n",
    "            # Number of possible discrete rating values in this task\n",
    "            M = 7\n",
    "        # Number of instances\n",
    "        N = len(df)\n",
    "        # Number of columns(subtract the username column)\n",
    "        C = len(df.columns)\n",
    "        # Number of all cells in the dataset that are not na\n",
    "        num_all_non_na_cells = C*N - df.isna().values.sum()\n",
    "        nominator = 0.0\n",
    "        values, counts = np.unique(df.values, return_counts=True)\n",
    "        # Only get actual values, not the nan - values\n",
    "        values = values[:M]\n",
    "        counts = counts[:M]\n",
    "        for i, c in enumerate(counts):\n",
    "            rating_ratio = (c / num_all_non_na_cells)\n",
    "            nominator += ( rating_ratio * log(rating_ratio) )\n",
    "        \n",
    "        return (-nominator / log(M))\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_training_error(error:[float], **kwargs) -> None: \n",
    "            \"\"\" \n",
    "            Plots the training error for every training iteration. \n",
    "             \n",
    "            Params: \n",
    "                error (list): A list of error - values that correspond to each training iteration of the TLMF - algorithm.     \n",
    "            **kwargs: Arbitrary many keyword arguments to customize the plot. E.g. color, linewidth or title. \n",
    "            \"\"\"  \n",
    "            plt.plot([i for i in range(1, len(error)+1)], error) \n",
    "            for k in kwargs.keys(): \n",
    "                # Invoke the function k of the plt - module to customize the plot \n",
    "                getattr(plt, k) (kwargs[k])\n",
    "            \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graphics = Graphics()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c4321509887871942225181aea45e229e5aed2157cb28edcc519edea6ae29dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('ba_thesis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
