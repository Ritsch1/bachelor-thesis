{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# imports\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from IPython.core.debugger import set_trace\r\n",
    "import torch\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import subprocess"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Export notebook as python script to the ../python-code - folder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "subprocess.run(\"jupyter nbconvert --output-dir='../python-code' --to python TLMF.ipynb --TemplateExporter.exclude_markdown=True --TemplateExporter.exclude_input_prompt=True\", shell=True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CompletedProcess(args=\"jupyter nbconvert --output-dir='../python-code' --to python TLMF.ipynb --TemplateExporter.exclude_markdown=True --TemplateExporter.exclude_input_prompt=True\", returncode=0)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TLMF - Algorithm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class TLMF():\r\n",
    "    \"\"\"\r\n",
    "    A class that represents the Two-Level-Matrix-Factorization (TLMF).\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    def __init__(self, wtmf, rmh, mode:str=\"Conviction\"):\r\n",
    "        \"\"\"\r\n",
    "        Params:\r\n",
    "            wtmf (WTMF): A wtmf (Weighted Text Matrix Factorization) - object. This object represents the first level of the TLMF. It contains the argument similarity matrix which is used in TLMF.\r\n",
    "            rmh (Rating_Matrix_Handler): A Rating_Matrix_Handler object that contains the final rating matrix that consists of the training data - entires as well as the masked test data - entries and which\r\n",
    "            is used for optimizing the TLMF on. It also contains the indices of the original test-set in order to perform evaluation.\r\n",
    "            mode (str, optional): The task on which the tlmf-model is trained. Depending on the task it is trained on other subsets of data. Can take values ['Conviction','Weight']\r\n",
    "            Defaults to 'Conviction'.\r\n",
    "        \"\"\"\r\n",
    "        self.wtmf = wtmf\r\n",
    "        self.rmh = rmh\r\n",
    "        # Initialize GPU for computation if available            \r\n",
    "        machine = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\r\n",
    "        self.device = torch.device(machine)\r\n",
    "        # Assertions\r\n",
    "        assert(mode == \"Conviction\" or mode == \"Weight\"), f\"Unkown task - description {mode} was passed.\"\r\n",
    "        self.mode_ = mode\r\n",
    "\r\n",
    "    def train(self, d:int=20, training_iterations:int=50, random_seed:int=1, print_frequency:int=1, r:float=0.05, lambda_:float=0.01, alpha:float=0.2, n:int=10) -> [float]:\r\n",
    "        \"\"\"\r\n",
    "        Use stochastic gradient descent to find the two optimal latent factor matrices U (Users), I (Items) \r\n",
    "        that minimizes the difference between the predicted values of the dot product of user-vectors and item-vectors compared to the known ratings in the user-item matrix.\r\n",
    "        \r\n",
    "        Params:\r\n",
    "            d (int, optional): The embedding dimension of the user and item vectors within the latent factor matrices. Defaults to 20.\r\n",
    "            training_iterations (int, optional): The number of training iterations over known user-item ratings. Defaults to 50.\r\n",
    "            random_seed (int, optional):  Random seed that is used to intialize the latent factor matrices. Defaults to 1.. Defaults to 1.\r\n",
    "            print_frequency (int, optional): The frequency in which the training error is printed w.r.t. to the iterations. Defaults to 1.\r\n",
    "            r (float, optional): The regularization factor that controls the overfitting of the model. Defaults to 0.05.\r\n",
    "            lambda_ (float, optional): The learning rate, a parameter that determines how heavily the vectors of the latent factor matrices are updated in every iteration. Defaults to 0.01.\r\n",
    "            alpha (float, optional): The parameter that controls the influence of the semantic relations of the items in the prediction. Defaults to 0.02.\r\n",
    "            n (int, optional): The n most similar items to item i that are considered for any prediction in which item i is involved.\r\n",
    "            \r\n",
    "        Returns:\r\n",
    "            [float]: A list containing the error values for every iteration.\r\n",
    "        \"\"\"\r\n",
    "        if self.mode_==\"Conviction\":\r\n",
    "            # Select all conviction columns with values in the range [0,1]\r\n",
    "            # Get all relevant column-indices\r\n",
    "            idxs = torch.arange(1, self.rmh.final_rating_matrix.shape[1], 2)\r\n",
    "            trimmed_rating_matrix = torch.index_select(self.rmh.final_rating_matrix, 1, idxs)\r\n",
    "        elif self.mode_==\"Weight\":\r\n",
    "            # Select all weight columns with values in the range [0,6]\r\n",
    "            # Get all relevant column-indices\r\n",
    "            idxs = torch.arange(0, self.rmh.final_rating_matrix.shape[1], 2)           \r\n",
    "            trimmed_rating_matrix = torch.index_select(self.rmh.final_rating_matrix, 1, idxs)\r\n",
    "        \r\n",
    "        # Set random seed for reproducability\r\n",
    "        torch.manual_seed(random_seed)\r\n",
    "        \r\n",
    "        # Randomly initialize the latent factor matrices U(ser) and I(tems)\r\n",
    "        self.U = torch.rand([trimmed_rating_matrix.shape[0], d]).to(self.device)\r\n",
    "        self.I = torch.rand([trimmed_rating_matrix.shape[1], d]).to(self.device)\r\n",
    "        \r\n",
    "        # Error - variable: keep track of each error in every iteration for later visualization \r\n",
    "        error = []\r\n",
    "        error_cur = 0.0\r\n",
    "        frobenius_norm = torch.linalg.matrix_norm\r\n",
    "\r\n",
    "        # Get non-na indices of rating - matrix to train TLMF on\r\n",
    "        training_indices = (~torch.isnan(trimmed_rating_matrix)).nonzero().to(torch.int).to(self.device)\r\n",
    "        sample_counter = 0\r\n",
    "        for iteration in range(training_iterations):\r\n",
    "            for idx in training_indices:\r\n",
    "                sample_counter +=1\r\n",
    "                # Get the index of the current user within the training matrix\r\n",
    "                user = idx[0]\r\n",
    "                # Get the index of the current argument within the training matrix\r\n",
    "                arg = idx[1]\r\n",
    "                # Get the column- indices of the n items that are most similar to the current item in the argument similarity matrix\r\n",
    "                most_sim_indices = torch.topk(self.wtmf.similarity_matrix[arg], n, dim=0, sorted=False)[1]\r\n",
    "                \r\n",
    "                ######## \r\n",
    "                # Calculate the sum of similarities over the n most similar args\r\n",
    "                ########\r\n",
    "                sim_sum_scaled = torch.zeros(self.I[arg].shape)\r\n",
    "                    \r\n",
    "                for arg_neighbor_index, sim_value in enumerate(most_sim_indices):\r\n",
    "                    sim_sum_scaled = torch.add(sim_sum_scaled, torch.mul(self.I[arg_neighbor_index], self.wtmf.similarity_matrix[arg][arg_neighbor_index]))\r\n",
    "                    \r\n",
    "                sim_sum_scaled = torch.sub(self.I[arg], sim_sum_scaled)\r\n",
    "                sim_sum_scaled = torch.matmul(sim_sum_scaled, sim_sum_scaled.T)\r\n",
    "                sim_sum_scaled = torch.mul(sim_sum_scaled, alpha)\r\n",
    "                    \r\n",
    "                prediction = self.U[user].matmul(self.I.T[:,arg])\r\n",
    "                true_value = trimmed_rating_matrix[user][arg]\r\n",
    "                \r\n",
    "                difference = true_value - prediction\r\n",
    "                error_cur += torch.pow(difference,2) + (r/2 * (frobenius_norm(self.U) + frobenius_norm(self.I))) + sim_sum_scaled\r\n",
    "\r\n",
    "                # Save old value of the user - vector for updating the item - vector (TODO: Not sure if I should already use the updated user-vector for updating the item vector)\r\n",
    "                old_user_vector = self.U[user]\r\n",
    "\r\n",
    "                # Update the user-vector\r\n",
    "                self.U[user] = torch.add(self.U[user], torch.mul((torch.sub(torch.mul(self.I[arg], difference), torch.mul(self.U[user], r))), lambda_))\r\n",
    "                                        \r\n",
    "                ########\r\n",
    "                # Calculate the similarity sum components to update the item latent vector (equation 16)\r\n",
    "                ########\r\n",
    "                # First component\r\n",
    "                sim_sum = torch.zeros(self.I[arg].shape)\r\n",
    "                for arg_neighbor_idx in most_sim_indices:\r\n",
    "                   sim_sum = torch.add(sim_sum, torch.mul(self.I[arg_neighbor_idx], self.wtmf.similarity_matrix[arg][arg_neighbor_idx])) \r\n",
    "                sim_sum = torch.sub(self.I[arg], sim_sum)\r\n",
    "                sim_sum = torch.mul(sim_sum, alpha)\r\n",
    "                \r\n",
    "                # Second component\r\n",
    "                sim_sum2 = torch.zeros(self.I[arg].shape)\r\n",
    "                # Calculate the most similar arg-indices to the neighbor args\r\n",
    "                # Create a list to hold a tuple of (neighour_arg_idx, list_of_similar_args_to_neighbor) of the args for every neighbor arg\r\n",
    "                most_sim_args_of_neighbors = [] \r\n",
    "                for idx, sim_arg in enumerate(most_sim_indices):\r\n",
    "                    most_sim_args_of_neighbors.append(torch.topk(self.wtmf.similarity_matrix[sim_arg], n, dim=0, sorted=False)[1])\r\n",
    "                    \r\n",
    "                for neighbor in most_sim_indices:\r\n",
    "                    for idxs in most_sim_args_of_neighbors:\r\n",
    "                        for neighbor_of_neighbor in idxs:\r\n",
    "                            #set_trace()\r\n",
    "                            sim_sum2 = torch.add(sim_sum2, torch.mul(self.I[neighbor_of_neighbor], self.wtmf.similarity_matrix[neighbor][neighbor_of_neighbor]))\r\n",
    "                        sim_sum2 = torch.sub(self.I[neighbor], sim_sum2)\r\n",
    "                        sim_sum2 = torch.mul(sim_sum2, self.wtmf.similarity_matrix[neighbor][arg])\r\n",
    "                    \r\n",
    "                sim_sum2 = torch.mul(sim_sum2, alpha)\r\n",
    "                sim_sum = torch.add(sim_sum, sim_sum2)\r\n",
    "                self.I[arg] = torch.add(self.I[arg], (torch.mul( torch.sub(torch.sub(torch.mul( self.U[user], difference), torch.mul(self.I[arg], r)), sim_sum), lambda_)))\r\n",
    "            try:\r\n",
    "                if error_cur > error[-1]:\r\n",
    "                    break\r\n",
    "            except:\r\n",
    "                pass\r\n",
    "                            \r\n",
    "            error.append(error_cur)\r\n",
    "            error_cur = 0.0\r\n",
    "                 \r\n",
    "            # Print out error w.r.t print-frequency\r\n",
    "            if (iteration + 1) % print_frequency == 0:\r\n",
    "                print(f\"Training - Error:{error[iteration]:.2f}\\tCurrent Iteration: {iteration+1}\\\\{training_iterations}\")\r\n",
    "       \r\n",
    "        return error\r\n",
    "\r\n",
    "    def calculate_mode_values(self, n:int=2) -> tuple:\r\n",
    "      \"\"\"\r\n",
    "      Calculates two dictionaries.\r\n",
    "      The first dictionary contains an argument index as key and the indices\r\n",
    "      of the n most similar arguments as a torch.tensor as value.\r\n",
    "      The second dictionary contains an argument index as key and the modal\r\n",
    "      value of this argument as a value.  \r\n",
    "      \r\n",
    "      Params:\r\n",
    "        n (int, optional): The number of similar arguments to consider.\r\n",
    "\r\n",
    "      Returns:\r\n",
    "        A tuple of two dictionaries, where the first dictionary is at index 0\r\n",
    "        and the second dictionary is at index 1.\r\n",
    "      \"\"\"\r\n",
    "      # First dictionary\r\n",
    "      sim_args_dict = {arg_idx: torch.topk(self.wtmf.similarity_matrix[arg_idx], n, dim=0, sorted=False)[1] for arg_idx in self.wtmf.similarity_matrix.shape[1]}\r\n",
    "      # Second dictionary\r\n",
    "      args_mode_dict = {arg_idx: torch.mode(self.trimmed_rating_matrix[:,arg_idx])[0] for arg_idx in sim_args_dict.keys()}\r\n",
    "\r\n",
    "      return (sim_args_dict, args_mode_dict)\r\n",
    "    \r\n",
    "    def evaluate(self) -> float:\r\n",
    "        \"\"\"\r\n",
    "        Returns:\r\n",
    "            float: A float that represents the error of the TLMF-model on the test set. \r\n",
    "        \"\"\"\r\n",
    "        \r\n",
    "        # Filter the evaluation indices based on the task\r\n",
    "        if self.mode_ == \"Conviction\":\r\n",
    "            #Get odd-indexed arguments that correspond to conviction arguments in the range [0,1]        \r\n",
    "            self.rmh.test_eval_indices = {user:items[items % 2 == 1] for user,items in self.rmh.test_eval_indices.items()}\r\n",
    "            # To match the indices of the training, integer divide all odd indices by 2 to map them to the correct index\r\n",
    "            for key, value in self.rmh.test_eval_indices.items():\r\n",
    "                self.rmh.test_eval_indices[key] = value // 2 \r\n",
    "            # Get rid of the username column in the test-rating -matrix for converting only numerical values into a pytorch tensor\r\n",
    "            test_rating_matrix_copy = self.rmh.test_rating_matrix.drop([\"username\"], axis=1)\r\n",
    "            # Trim the original test_rating_matrix to the conviction columns only\r\n",
    "            trimmed_test_rating_matrix = torch.index_select(torch.from_numpy(test_rating_matrix_copy.values).to(torch.float16), 1, torch.arange(1, test_rating_matrix_copy.shape[1], 2))\r\n",
    "            # Calculate the mean-accuracy for the Prediction of Conviction (PoC) - task \r\n",
    "            mean_acc = 0.0\r\n",
    "            # Variable for counting the correct 0/1 prediction\r\n",
    "            count_equality = 0\r\n",
    "            for username, test_samples in self.rmh.test_eval_indices.items():\r\n",
    "                # The actual username of the user\r\n",
    "                username_str = username[0]\r\n",
    "                # The row-index in the test set of that user\r\n",
    "                user_idx_test = username[1]\r\n",
    "                # Get the row-index for the user in the latent user-vector\r\n",
    "                user_idx_pred = self.rmh.final_rating_matrix_w_usernames[self.rmh.final_rating_matrix_w_usernames[\"username\"]==username_str].index[0]\r\n",
    "                for arg_idx in test_samples:\r\n",
    "                    # If the prediction is correct, increment the counter\r\n",
    "                    true_value = trimmed_test_rating_matrix[user_idx_test][arg_idx]\r\n",
    "                    prediction = torch.round(self.U[user_idx_pred].matmul(self.I[arg_idx].T))\r\n",
    "                    if  true_value == prediction:\r\n",
    "                        count_equality += 1\r\n",
    "                # Normalize by the number of test samples for this user\r\n",
    "                mean_acc += count_equality / len(test_samples)\r\n",
    "                # Set the count equality to 0 for the next user\r\n",
    "                count_equality = 0\r\n",
    "            # Normalize the error by the number of users in the test-set\r\n",
    "            mean_acc /= len(self.rmh.test_eval_indices)\r\n",
    "        \r\n",
    "            return mean_acc\r\n",
    "        \r\n",
    "        elif self.mode_==\"Weight\":\r\n",
    "            self.rmh.test_eval_indices = {user:items[items % 2 == 0] for user,items in self.rmh.test_eval_indices.items()}\r\n",
    "            # To match the indices of the training, integer divide all odd indices by 2 to map them to the correct index\r\n",
    "            for key, value in self.rmh.test_eval_indices.items():\r\n",
    "                self.rmh.test_eval_indices[key] = value // 2\r\n",
    "            # Get rid of the username column in the test-rating -matrix for proper indexing\r\n",
    "            test_rating_matrix_copy = self.rmh.test_rating_matrix.drop([\"username\"], axis=1) \r\n",
    "            # Trim the original test_rating_matrix to the weight columns only\r\n",
    "            trimmed_test_rating_matrix = torch.index_select(torch.from_numpy(test_rating_matrix_copy.values).to(torch.float16), 1, torch.arange(0, test_rating_matrix_copy.shape[1], 2))\r\n",
    "            # Calculate the averaged root mean squared error for the Prediction of Weight (PoW) - task\r\n",
    "            rmse_error = 0.0\r\n",
    "            # Variable for measuring the distance of the true value and the prediction\r\n",
    "            prediction_distance = 0.0\r\n",
    "            for username, test_samples  in self.rmh.test_eval_indices.items():\r\n",
    "                user_idx = username[1]\r\n",
    "                for arg_idx in test_samples:\r\n",
    "                    # If the prediction is correct, increment the counter\r\n",
    "                    prediction_distance += (trimmed_test_rating_matrix[user_idx][arg_idx] - torch.round(self.U[user_idx].matmul(self.I[arg_idx].T)))**2 \r\n",
    "                    # Normalize by the number of test samples for this user\r\n",
    "                rmse_error += prediction_distance / len(test_samples)\r\n",
    "                # Set the prediction distance to 0 for the next user\r\n",
    "                prediction_distance = 0\r\n",
    "            # Normalize the prediction_distance by the number of users in the test-set\r\n",
    "            rmse_error /= len(self.rmh.test_eval_indices)\r\n",
    "            \r\n",
    "            return rmse_error\r\n",
    "        \r\n",
    "    def plot_training_error(self, error:[float], **kwargs) -> None:\r\n",
    "        \"\"\"\r\n",
    "        Plots the training error for every training iteration.\r\n",
    "        \r\n",
    "        Params:\r\n",
    "            error (list): A list of error - values that correspond to each training iteration of the TLMF - algorithm.    \r\n",
    "            **kwargs: Arbitrary many keyword arguments to customize the plot. E.g. color, linewidth or title.\r\n",
    "        \"\"\" \r\n",
    "        plt.plot([i for i in range(1, len(error)+1)], error)\r\n",
    "        for k in kwargs.keys():\r\n",
    "            # Invoke the function k of the plt - module to customize the plot\r\n",
    "            getattr(plt, k) (kwargs[k])\r\n",
    "        \r\n",
    "        plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "tags": [
     "parameters"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "k=20\r\n",
    "training_iterations=20\r\n",
    "weight=0.05\r\n",
    "gamma=0.001\r\n",
    "random_seed=8\r\n",
    "print_frequency=1\r\n",
    "%run WTMF.ipynb"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error:436.81\tCurrent Iteration: 1\\20\n",
      "Error:296.09\tCurrent Iteration: 2\\20\n",
      "Error:279.33\tCurrent Iteration: 3\\20\n",
      "Error:270.02\tCurrent Iteration: 4\\20\n",
      "Error:263.53\tCurrent Iteration: 5\\20\n",
      "Error:258.55\tCurrent Iteration: 6\\20\n",
      "Error:254.50\tCurrent Iteration: 7\\20\n",
      "Error:251.07\tCurrent Iteration: 8\\20\n",
      "Error:248.07\tCurrent Iteration: 9\\20\n",
      "Error:245.40\tCurrent Iteration: 10\\20\n",
      "Error:242.99\tCurrent Iteration: 11\\20\n",
      "Error:240.77\tCurrent Iteration: 12\\20\n",
      "Error:238.72\tCurrent Iteration: 13\\20\n",
      "Error:236.81\tCurrent Iteration: 14\\20\n",
      "Error:235.02\tCurrent Iteration: 15\\20\n",
      "Error:233.33\tCurrent Iteration: 16\\20\n",
      "Error:231.73\tCurrent Iteration: 17\\20\n",
      "Error:230.21\tCurrent Iteration: 18\\20\n",
      "Error:228.76\tCurrent Iteration: 19\\20\n",
      "Error:227.37\tCurrent Iteration: 20\\20\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Parameters for executing the Rating-Matrix-Handler notebook\r\n",
    "train_path = f\"C:/Users/Rico/Desktop/bachelor-thesis/data/T1_T2/train.csv\"\r\n",
    "test_path  = f\"C:/Users/Rico/Desktop/bachelor-thesis/data/T1_T2/test.csv\"\r\n",
    "%run Rating_Matrix_Handler.ipynb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def random_search(tlmf:TLMF, num_experiments:int=10, **param_values) -> dict:\r\n",
    "    \"\"\"\r\n",
    "    Perform a random search for the best parameter-values for the tlmf algorithm.\r\n",
    "    \r\n",
    "    Params:\r\n",
    "        tlmf (TLMF): A TLMF-object containing that is used to predict the unknown ratings.\r\n",
    "        num_experiments: The number of optimization experiments with random parameter values that should be carried out.\r\n",
    "        **param_values (kwargs): A dictionary of keys(parameter_name) and values (list of values to try out for that parameter).\r\n",
    "        \r\n",
    "    Returns: A list of tuples containing the prediction - score on index 0 and the parameter-values on index 1. \r\n",
    "    \"\"\"\r\n",
    "    # List containing tuples of (score, parameter-values) \r\n",
    "    results = []\r\n",
    "    for i in range(num_experiments):\r\n",
    "        print(f\"Experiment {i+1}:\\n\")\r\n",
    "        # Parameters for executing the Rating-Matrix-Handler notebook\r\n",
    "        train_path = f\"C:/Users/Rico/Desktop/bachelor-thesis/data/T1_T2/train.csv\"\r\n",
    "        test_path  = f\"C:/Users/Rico/Desktop/bachelor-thesis/data/T1_T2/test.csv\"\r\n",
    "        %run Rating_Matrix_Handler.ipynb\r\n",
    "        tlmf = TLMF(tlmf.wtmf, rmh)\r\n",
    "        # Set parameters to random values\r\n",
    "        execution_dict = {param:np.random.choice(values) for param, values in param_values.items()}\r\n",
    "        # Run training    \r\n",
    "        train_error = tlmf.train(**execution_dict)\r\n",
    "        test_result = tlmf.evaluate()\r\n",
    "        results.append((test_result, execution_dict))\r\n",
    "    return results"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "tlmf = TLMF(wtmf, rmh)\r\n",
    "params = {\"d\":np.array([12, 13, 14, 15, 16, 17]),\r\n",
    "          \"alpha\":np.array([0.00001, 0.001]),\r\n",
    "          \"n\":np.array([1,2,3]),\r\n",
    "          \"training_iterations\":np.array([10, 20, 50, 100]), \r\n",
    "          \"random_seed\":np.array([8, 9, 11]), \r\n",
    "          \"print_frequency\":np.array([10]), \r\n",
    "          \"r\":np.array([0.01, 0.001, 0.005, 0.008, 0.0001, 0.00001]), \r\n",
    "          \"lambda_\":np.array([0.1, 0.01, 0.02, 0.001, 0.005, 0.008, 0.0001, 0.00001])\r\n",
    "          }\r\n",
    "results = random_search(tlmf, num_experiments=1, **params)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Experiment 1:\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14248/2360438781.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m           \u001b[1;34m\"lambda_\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.02\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.008\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.00001\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m           }\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtlmf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_experiments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14248/2001066338.py\u001b[0m in \u001b[0;36mrandom_search\u001b[1;34m(tlmf, num_experiments, **param_values)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mexecution_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparam_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# Run training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mtrain_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtlmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mexecution_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mtest_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtlmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecution_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14248/1856773381.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, d, training_iterations, random_seed, print_frequency, r, lambda_, alpha, n)\u001b[0m\n\u001b[0;32m    122\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0mneighbor_of_neighbor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0midxs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                             \u001b[1;31m#set_trace()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m                             \u001b[0msim_sum2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_sum2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneighbor_of_neighbor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwtmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilarity_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneighbor_of_neighbor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m                         \u001b[0msim_sum2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim_sum2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[0msim_sum2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_sum2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwtmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilarity_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "9c4321509887871942225181aea45e229e5aed2157cb28edcc519edea6ae29dd"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('ba_thesis': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}