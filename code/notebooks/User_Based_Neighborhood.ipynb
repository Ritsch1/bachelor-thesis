{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export notebook as python script to the ../python-code - folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=\"jupyter nbconvert --output-dir='../python-code' --to python User_Based_Neighborhood.ipynb --TemplateExporter.exclude_markdown=True --TemplateExporter.exclude_input_prompt=True\", returncode=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\"jupyter nbconvert --output-dir='../python-code' --to python User_Based_Neighborhood.ipynb --TemplateExporter.exclude_markdown=True --TemplateExporter.exclude_input_prompt=True\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neighborhood_Model(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for all neighborhood based models. The 'predict', and the 'compute_similarity' - functions need to be implemented by inheriting classes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, rmh, task:str=\"Conviction\"):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "            rmh (Rating_Matrix_Handler): A Rating_Matrix_Handler object that provides the relevant rating matrices as well as test indices.\n",
    "            task (str): The task that the model should predict on. Defaults to \"Conviction\".\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.rmh_ = rmh\n",
    "        self.task_ = task\n",
    "        arg_range = [x for x in range(324,400) if x != 397]\n",
    "        if self.task_ == \"Conviction\":\n",
    "            self.task_train_rating_matrix = self.rmh_.final_rating_matrix_w_usernames[[\"username\"] + [f\"statement_attitude_{i}\" for i in arg_range]]\n",
    "            self.task_test_rating_matrix = self.rmh_.test_rating_matrix[[\"username\"] + [f\"statement_attitude_{i}\" for i in arg_range]]\n",
    "            self.test_eval_indices = {user:items[items % 2 == 1] for user,items in self.rmh_.test_eval_indices.items()}\n",
    "        else:\n",
    "            self.task_train_rating_matrix = self.rmh_.final_rating_matrix_w_usernames[[\"username\"] + [f\"argument_rating_{i}\" for i in arg_range]]\n",
    "            self.task_test_rating_matrix = self.rmh_.test_rating_matrix[[\"username\"] + [f\"argument_rating_{i}\" for i in arg_range]]\n",
    "            self.test_eval_indices = {user:((items[items % 2 == 0] // 2) + 1) for user,items in self.rmh_.test_eval_indices.items()}\n",
    "    \n",
    "    def build_lookups(self) -> None:\n",
    "        \"\"\"\n",
    "        Map users and items to numerical values for further indexing.\n",
    "        \"\"\"\n",
    "        self.userid_lookup_ = {username: i for i, username in enumerate(self.task_train_rating_matrix[\"username\"])}\n",
    "        self.itemid_lookup_ = {item: i for i, item in enumerate(list(self.task_train_rating_matrix.columns))}\n",
    "        # Reverse the two calculated mappings for bidirectional lookup\n",
    "        self.username_lookup_ = {user_id: username for username, user_id in self.userid_lookup_.items()}\n",
    "        self.itemname_lookup_ = {item_id: itemname for itemname, item_id in self.itemid_lookup_.items()}\n",
    "        \n",
    "    def calculate_items_rated_by_user(self) -> None:\n",
    "        \"\"\"\n",
    "        Calculate a dictionary containing usernames as keys and a numpy array of rated items as key.\n",
    "        \"\"\"\n",
    "        self.items_rated_by_user = {}\n",
    "        users = set(self.userid_lookup_.keys())\n",
    "        for u in users:\n",
    "            # Calculate the item-indices that are non-na for each user\n",
    "            self.items_rated_by_user[self.userid_lookup_[u]] = np.argwhere(~pd.isna(self.task_train_rating_matrix[self.task_train_rating_matrix[\"username\"] == u]).values)[:,1][1:]\n",
    "        for rated_items in self.items_rated_by_user.values():\n",
    "            # Delete the first entry, as its the username which will not be used for similarity computation\n",
    "            rated_items = rated_items[1:]\n",
    "            \n",
    "    \n",
    "    def compute_mean_ratings(self, for_users:bool=True) -> None:\n",
    "        \"\"\"\n",
    "        Compute the mean rating for users/items depending on the for_users - flag as a dictionary with users/items as key and the average rating as value.\n",
    "\n",
    "        Params:\n",
    "            for_users (bool, optional): If set to True, calculate user-rating means. If set to False, calculate item-rating means. Defaults to True.\n",
    "        \"\"\"\n",
    "        self.user_mean_ratings, self.item_mean_ratings = {}, {}\n",
    "        \n",
    "        for username, user_id in self.userid_lookup_.items():\n",
    "            self.user_mean_ratings[user_id] = np.nanmean(np.array(self.task_train_rating_matrix[self.task_train_rating_matrix[\"username\"] == username].values[0][1:],dtype=float))\n",
    "    \n",
    "        # Exclude the username column\n",
    "        for item in self.task_train_rating_matrix.columns[1:]:\n",
    "            self.item_mean_ratings[self.itemid_lookup_[item]] = np.nanmean(self.task_train_rating_matrix[item].values)\n",
    "    \n",
    "    def compute_mutual_objects(self, iterable1:Iterable, iterable2:Iterable) -> set:\n",
    "        \"\"\"\n",
    "        Computes the mutual objects of two iterables.\n",
    "\n",
    "        Args:\n",
    "            iterable1 (Iterable): First iterable object.\n",
    "            iterable2 (Iterable): Second iterable object.\n",
    "\n",
    "        Returns:\n",
    "            set: The mutual objects of the first and second iterable object.\n",
    "        \"\"\"\n",
    "        return set(iterable1).intersection(set(iterable2))\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, user:str, item:str) -> int:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def compute_similarity(self, object1, object2) -> float:\n",
    "        \"\"\"\n",
    "        Compute the similarity between the ratings of both objects. As the similarity is only computed over mutual ratings of both objects, the dimension of both rating vectors must be equal.\n",
    "\n",
    "        Args:\n",
    "            ratings1 (np.array): First object.\n",
    "            ratings2 (np.array): Second object.\n",
    "\n",
    "        Returns:\n",
    "            float: Similarity score of both rating vectors.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def compute_similarity_matrix(self) -> np.array:\n",
    "        pass\n",
    "\n",
    "    def evaluate(self, k:int, similarity_threshold:float) -> float:\n",
    "        pass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User_Neighborhood_Pearson_Centered(Neighborhood_Model):\n",
    "    \"\"\"\n",
    "    A user - based neighborhood model that takes into account rating bias by centering the raw data for each user and applying the Pearson Correlation Coefficient for predicting the similarity of user-pairs. \n",
    "    \"\"\"\n",
    "    def __init__(self, rmh, task='Conviction'):\n",
    "        super().__init__(rmh, task=task)\n",
    "        if self.task_ == \"Conviction\":\n",
    "            # Subtract the row - mean from all values in that row\n",
    "            self.mean_centered_train_rating_matrix = self.task_train_rating_matrix.drop(\"username\", axis=1).sub(self.task_train_rating_matrix.drop(\"username\", axis=1).mean(axis=1), axis=0).values\n",
    "        else:\n",
    "            # Subtract the row mean from all the values in that row\n",
    "            self.mean_centered_train_rating_matrix = self.task_train_rating_matrix.drop(\"username\", axis=1).sub(self.task_train_rating_matrix.drop(\"username\", axis=1).mean(axis=1), axis=0).values\n",
    "    \n",
    "    def compute_similarity(self, user1:int, user2:int, similarity_function:str=\"Pearson\") -> float:\n",
    "        \"\"\"\n",
    "        Compute the Pearson Correlation Coefficient for the two rating vectors.\n",
    "\n",
    "        Args:\n",
    "            user1 (int): First user.\n",
    "            user2 (int): Second user.\n",
    "            similarity_function (str): Function that is used to compute the similarity of two users. Can either be RawCosine, RawCosineDiscounted, Pearson. Defaults to Pearson.\n",
    "        Returns:\n",
    "            float: Pearson Correlation Coefficient of both rating vectors.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get rated items of both users\n",
    "        rated_items1 = self.items_rated_by_user[user1]\n",
    "        rated_items2 = self.items_rated_by_user[user2]\n",
    "     \n",
    "        # Get mutual rated items\n",
    "        mutual_rated_items = self.compute_mutual_objects(rated_items1, rated_items2)\n",
    "        # If there are no mutual rated items, return 0 for the Pearson Correlation Coefficient\n",
    "        if len(mutual_rated_items) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        if similarity_function == \"RawCosine\":\n",
    "            ratings = []\n",
    "            for item in mutual_rated_items:\n",
    "                r_u1 = int(self.task_train_rating_matrix[self.task_train_rating_matrix[\"username\"] == self.username_lookup_[user1]][self.itemname_lookup_[item]])\n",
    "                r_u2 = int(self.task_train_rating_matrix[self.task_train_rating_matrix[\"username\"] == self.username_lookup_[user2]][self.itemname_lookup_[item]])\n",
    "                ratings.append( (r_u1, r_u2))\n",
    "        \n",
    "            ratings = np.array(ratings)\n",
    "            nominator = np.sum(ratings[:,0] * ratings[:,1])\n",
    "            denominator = np.sqrt(np.sum(ratings[:,0]**2)) * np.sqrt(np.sum(ratings[:,1]**2))\n",
    "            return nominator / denominator\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            # Get mean rating of both users\n",
    "            mean_rating1 = self.user_mean_ratings[user1]\n",
    "            mean_rating2 = self.user_mean_ratings[user2]\n",
    "            \n",
    "            # Variable holding the difference between actual rating and mean rating for both users, as this value needs to be calculated multiple times\n",
    "            diffs = []\n",
    "            for i, item in enumerate(mutual_rated_items):\n",
    "                # Decrement item id by 1 as the train rating matrix still contains the username\n",
    "                r_u1 = int(self.task_train_rating_matrix[self.task_train_rating_matrix[\"username\"] == self.username_lookup_[user1]][self.itemname_lookup_[item]])\n",
    "                r_u2 = int(self.task_train_rating_matrix[self.task_train_rating_matrix[\"username\"] == self.username_lookup_[user2]][self.itemname_lookup_[item]])\n",
    "                diffs.append( (r_u1 - mean_rating1, r_u2 - mean_rating2) )\n",
    "            \n",
    "            # Calculate the nominator and denominator of the Pearson Correlation Coefficient\n",
    "            # Transform the list into numpy-array for indexing\n",
    "            diffs = np.array(diffs)\n",
    "            nominator = np.sum(diffs[:,0] * diffs[:,1])\n",
    "            denominator = np.sqrt(np.sum(diffs[:,0]**2) * np.sum(diffs[:,1]**2))\n",
    "            \n",
    "           # Catch division by zero        \n",
    "            similarity =  similarity if not np.isnan((similarity := nominator / denominator)) else 0.0 \n",
    "\n",
    "            return similarity\n",
    "        \n",
    "    def compute_similarity_matrix(self):\n",
    "        \"\"\"\n",
    "        Compute a dictionary containing the target-user name as key and a dictionary {user_id:similarity_value} as value for the corresponding similarity value with other users.\n",
    "        \"\"\"\n",
    "        super().compute_similarity_matrix()\n",
    "        similarity_values = []\n",
    "        users = self.userid_lookup_.values()\n",
    "        counter = 1\n",
    "        for target_user in users:\n",
    "            print(f\"Computation started for user {counter}\")\n",
    "            similarity_values_target_user = []\n",
    "            for user in users:\n",
    "                # Set the similarity value of target user with himself to -1 to ensure that his ratings are not used for himself in the prediction\n",
    "                if target_user == user:\n",
    "                    similarity_values_target_user.append( (user, -1) ) \n",
    "                else:\n",
    "                    similarity_values_target_user.append( (user, self.compute_similarity(target_user, user)) ) \n",
    "        \n",
    "            similarity_values.append(similarity_values_target_user)\n",
    "            counter += 1\n",
    "            \n",
    "        # Convert the list of lists to a 2d - numpy array for later processing    \n",
    "        self.pearson_correlation_matrix = np.array(similarity_values)\n",
    "\n",
    "    def calculate_k_closest_users(self, item:int, target_user:int, k:int, similarity_threshold:float, threshold_decrease_rate:float) -> np.array:\n",
    "        \"\"\"\n",
    "        Calculate the k-closest users to the target-user that rated the same item and whose similarity value is above the similarity threshold.\n",
    "        \n",
    "        Params:\n",
    "            item (int): The item-id for which the k closest users have to be found w.r.t. the target-user.\n",
    "            target_user (int): The target user-id for which the k-closest users have to be found.\n",
    "            k (int): The upper bound of the number of users that should be included in the final set. \n",
    "            similarity_threshold (float): A similarity threshold to set the minimum degree of similarity that a user has to have in order to be included in the final set.\n",
    "            threshold_decrease_rate (float): If there are no users with a similarity value above the threshold, decrease the threshold by this rate until there are users with above the new threshold value.\n",
    "        Returns:\n",
    "            np.array: A numpy array containing tuples [user_id, similarity_value].\n",
    "        \"\"\"\n",
    "        # Get array of similarities for target user\n",
    "        user_similarities = self.pearson_correlation_matrix[target_user]\n",
    "        # Get all users with their rated items\n",
    "        users_rated_items = tuple(self.items_rated_by_user.items())\n",
    "        # Filter for all users that have rated the same item\n",
    "        users_that_rated = np.array([user_id for user_id, rated_items in users_rated_items if item in rated_items])\n",
    "        # Get all indices of users where pearson similarity >= threshold\n",
    "        users_sim_bigger_thresh = user_similarities[user_similarities[:,1] >= similarity_threshold]\n",
    "        # Build intersection of users who rated the item and whose similarity value >= threshold\n",
    "        user_set = np.intersect1d(users_that_rated, users_sim_bigger_thresh[:,0])\n",
    "        # Sort depending on the similarity value\n",
    "        user_similarities = user_similarities[user_similarities[:, 1].argsort()]\n",
    "        # Depending on the size of the set, return the final [user-ids, similarity-value] tuples\n",
    "        if len(user_similarities >= k):\n",
    "            return user_similarities[-k:]\n",
    "        else:\n",
    "            return user_similarities\n",
    "    \n",
    "    def predict(self, target_user:int, item:int, k:int, similarity_threshold:float, threshold_decrease_rate:float) -> int:\n",
    "        \"\"\"\n",
    "        Params:\n",
    "            target_user (int): The target user-id for which the k-closest users have to be found.\n",
    "            item (int): The item-id for which the k closest users have to be found w.r.t. the target-user.\n",
    "            k (int): The upper bound of the number of users that should be included in the final set.\n",
    "            similarity_threshold (float): A similarity threshold to set the minimum degree of similarity that a user has to have in order to be included in the final set.\n",
    "            threshold_decrease_rate (float): If there are no users with a similarity value above the threshold, decrease the threshold by this rate until there are users with above the new threshold value.\n",
    "\n",
    "        Returns:\n",
    "            int: A discrete numerical value for this (user,item) - pair.\n",
    "        \"\"\"\n",
    "        super().predict(target_user, item)\n",
    "        # Get the k -closest [user_id, similarity_value] - tuples for the target-user and item \n",
    "        k_closest_users = self.calculate_k_closest_users(item, target_user, k, similarity_threshold, threshold_decrease_rate)\n",
    "        # Calculate the mean-centered prediction\n",
    "        nominator = []\n",
    "        denominator = []\n",
    "        \n",
    "        # If there were no users in the similarity set, return the mean of the item\n",
    "        if len(k_closest_users) == 0:\n",
    "            return round(self.item_mean_ratings[item])\n",
    "        \n",
    "        for user in k_closest_users[:,0]:\n",
    "            user_int = int(user)\n",
    "            item_int = int(item)\n",
    "            pearson_correlation = self.pearson_correlation_matrix[target_user][user_int][1]\n",
    "            denominator.append(abs(pearson_correlation))\n",
    "            # Decrement item by 1 as the mean_centered_train_rating_matrix does not contain the username column anymore\n",
    "            nominator.append(pearson_correlation * self.mean_centered_train_rating_matrix[user_int][item_int-1])\n",
    "        \n",
    "        nominator = sum(nominator)\n",
    "        denominator = sum(denominator)\n",
    "        pearson_normalized = pearson if not np.isnan((pearson := nominator / denominator)) else 0.0\n",
    "        \n",
    "        # Add the mean rating of the target - user\n",
    "        pearson_normalized += self.user_mean_ratings[target_user]\n",
    "        return pearson_normalized\n",
    "    \n",
    "    def evaluate(self, k:int, similarity_threshold:float, threshold_decrease_rate:float) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the performance of the model on the test dataset for a specific task.\n",
    "\n",
    "        Params:\n",
    "            k (int): The upper bound of the number of users that should be included in the final set.\n",
    "            similarity_threshold (float): A similarity threshold to set the minimum degree of similarity that a user has to have in order to be included in the final set.\n",
    "            threshold_decrease_rate (float): If there are no users with a similarity value above the threshold, decrease the threshold by this rate until there are users with above the new threshold value.\n",
    "            \n",
    "        Returns:\n",
    "            float: RMSE if task is \"Weight\" and mean accuracy if task is \"Conviction\".\n",
    "        \"\"\"\n",
    "        trues, preds = [], []\n",
    "        # Filter the evaluation indices based on the task\n",
    "        if self.task_ == \"Conviction\":\n",
    "            # Calculate the mean-accuracy for the Prediction of Conviction (PoC) - task \n",
    "            mean_acc = 0.0\n",
    "            # Variable for counting the correct 0/1 prediction\n",
    "            count_equality = 0\n",
    "            for username, test_samples in self.test_eval_indices.items():\n",
    "                # Get the target-user id\n",
    "                target_user_id = self.userid_lookup_[username[0]]\n",
    "                for item_id in test_samples:\n",
    "                # Look up the true value\n",
    "                    true_value = self.task_test_rating_matrix[self.task_test_rating_matrix[\"username\"] == username[0]][self.itemname_lookup_[item_id]]\n",
    "                    prediction = round(self.predict(target_user_id, item_id, k, similarity_threshold, threshold_decrease_rate))\n",
    "                    preds.append(prediction)\n",
    "                    trues.append(true_value)\n",
    "                    # If the prediction is correct, increment the counter\n",
    "                    if int(true_value) == prediction:\n",
    "                        count_equality += 1\n",
    "                # Normalize by the number of test samples for this user\n",
    "                mean_acc += count_equality / len(test_samples)\n",
    "                # Set the count equality to 0 for the next user\n",
    "                count_equality = 0\n",
    "            # Normalize the error by the number of users in the test-set\n",
    "            mean_acc /= len(self.test_eval_indices)\n",
    "            print(f\"Accuracy: {mean_acc:.3f}\")\n",
    "            \n",
    "            return np.array(trues), np.array(preds)\n",
    "        \n",
    "        else:\n",
    "            rmse_error, prediction_distance = 0.0, 0.0\n",
    "            for username, test_samples in self.test_eval_indices.items():\n",
    "                # Get the target-user-id\n",
    "                target_user_id = self.userid_lookup_[username[0]]\n",
    "                for item_id in test_samples:\n",
    "                    # Look up the true value\n",
    "                    true_value = self.task_test_rating_matrix[self.task_test_rating_matrix[\"username\"] == username[0]][self.itemname_lookup_[item_id]]\n",
    "                    prediction = round(self.predict(target_user_id, item_id, k, similarity_threshold, threshold_decrease_rate))\n",
    "                    preds.append(prediction)\n",
    "                    trues.append(true_value)\n",
    "                    prediction_distance += (int(true_value) - prediction)**2\n",
    "                # Normalize by the number of test samples for this user     \n",
    "                rmse_error += (prediction_distance / len(test_samples))\n",
    "                # Set the prediction distance to 0 for the next user\n",
    "                prediction_distance = 0\n",
    "            # Normalize the prediction_distance by the number of users in the test-set\n",
    "            rmse_error /= len(self.test_eval_indices)\n",
    "            print(f\"RMSE: {rmse_error:.3f}\")\n",
    "            \n",
    "            return np.array(trues), np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpc = User_Neighborhood_Pearson_Centered(rmh, task)\n",
    "unpc.build_lookups()\n",
    "unpc.calculate_items_rated_by_user()\n",
    "unpc.compute_mean_ratings()\n",
    "unpc.compute_similarity_matrix()\n",
    "trues, preds = unpc.evaluate(**user_neighborhood_config)\n",
    "%run MetricHelper.ipynb\n",
    "print(mh.calculate_average_metrics())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c4321509887871942225181aea45e229e5aed2157cb28edcc519edea6ae29dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('ba_thesis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
