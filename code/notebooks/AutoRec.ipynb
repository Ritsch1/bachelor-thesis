{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export notebook as python script to the ../python-code folder\n",
    "subprocess.run(\"jupyter nbconvert --output-dir='../python-code' --to python AutoRec.ipynb --TemplateExporter.exclude_markdown=True --TemplateExporter.exclude_input_prompt=True\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRec(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the AutoRec autoencoder model.\n",
    "    \"\"\"    \n",
    "    def __init__(self, input_dim:int, hidden_layer_dim:int, mask_value:int, learning_rate:float, \n",
    "                 epochs:int, rmh, task:str=\"Conviction\", random_seed:int=42):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "            input_dim (int): The input dimension of the user or item vector.\n",
    "            hidden_layer_dim (int): The size of neurons in the hidden layer. \n",
    "            mask_value (int): The value that is used for masking missing values in the input.\n",
    "            learning_rate (float): The learning rate that is initially used to update the weights of the network.\n",
    "            epochs (int): The number of times the data passes through the network in training.\n",
    "            task (str, optional): The task that the AutoRec model is trained on, can be \"Conviction\" or \"Weight\". Defaults to \"Conviction\".\n",
    "            random_seed (int, optional): The value that is used to set the random state of the model. Important for reproducing the results. Defaults to 42.\n",
    "        \"\"\"\n",
    "        super(AutoRec, self).__init__()\n",
    "        \n",
    "        # Variables to perform assertions on\n",
    "        checklist = [input_dim, hidden_layer_dim, epochs]\n",
    "        assert all([v > 0 for v in checklist + [learning_rate]]) & all([type(v) == int for v in checklist]), \\\n",
    "        \"Input dimension, epochs and hidden layer dimension need to be positive integers.\"\n",
    "        \n",
    "        # Initialize GPU for computation if available\n",
    "        machine = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.device = torch.device(machine)\n",
    "        \n",
    "        # Setting all configurable random seeds for reproducability\n",
    "        self.random_seed = random_seed\n",
    "        torch.manual_seed(self.random_seed)\n",
    "        random.seed(self.random_seed)\n",
    "        np.random.seed(self.random_seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.cuda.manual_seed(self.random_seed)\n",
    "        torch.cuda.manual_seed_all(self.random_seed)\n",
    "        \n",
    "        self.mask_value = mask_value\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        # Creating linear layers\n",
    "        self.inputLayer = torch.nn.Linear(input_dim, hidden_layer_dim, bias=True, device=self.device)\n",
    "        # input dimension equals output dimensions in autoencoders\n",
    "        self.outputLayer = torch.nn.Linear(hidden_layer_dim, input_dim, bias=True, device=self.device)\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs \n",
    "        self.rmh = rmh\n",
    "        self.task = task\n",
    "       \n",
    "        # Prepare the rating matrix\n",
    "        self.X = torch.nan_to_num(self.rmh.final_rating_matrix, nan=self.mask_value)\n",
    "        # Slice the rating matrix based on the task\n",
    "        self.X = self.X[:,1::2].to(self.device) if self.task == \"Conviction\" else self.X[:,::2].to(self.device)\n",
    "        self.X = self.X.type(torch.FloatTensor)\n",
    "       \n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate a reconstruction of the input tensor.\n",
    "\n",
    "        Params:\n",
    "            x (torch.Tensor): Masked user or item - vector.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Reconstruction of the masked user or item - vector.\n",
    "        \"\"\"\n",
    "        sigmoid = torch.nn.Sigmoid()\n",
    "        identity = torch.nn.Identity()\n",
    "        \n",
    "        hidden_layer_result = sigmoid(self.inputLayer(x))\n",
    "        x_reconstruction = self.outputLayer(hidden_layer_result)\n",
    "        # Mask the gradient during training\n",
    "        if self.training:\n",
    "            masked_positions = (x == self.mask_value)\n",
    "            for i, mask in enumerate(masked_positions):\n",
    "                if mask:\n",
    "                    self.inputLayer.weight[0][i].detach() \n",
    "                    self.inputLayer.weight[1][i].detach() \n",
    "            \n",
    "        return x_reconstruction\n",
    "    \n",
    "    def train(self) -> list:\n",
    "        \"\"\"\n",
    "        Train the AutoRec model.\n",
    "\n",
    "        Params:\n",
    "            X (torch.Tensor): The masked training dataset consisting of item or user vectors.\n",
    "        Returns:\n",
    "            List of error values for each iteration.\n",
    "        \"\"\"\n",
    "        error = 0.0\n",
    "        errors = []\n",
    "        optimizer = torch.optim.Adam(self.parameters(), self.learning_rate)\n",
    "        \n",
    "        i = 0\n",
    "        while i < self.epochs:\n",
    "            i += 1\n",
    "            for x in self.X.T:\n",
    "                x_reconstruction = self.forward(x)\n",
    "                \n",
    "                idx_non_masked_entries = torch.where(~(x == self.mask_value))[0]\n",
    "                num_non_masked_entries = len(idx_non_masked_entries)\n",
    "                # If all entries of a column are null \n",
    "                if num_non_masked_entries == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                  loss = torch.div(torch.sum(torch.pow((x[idx_non_masked_entries] - x_reconstruction[idx_non_masked_entries]), 2)), num_non_masked_entries) \n",
    "                  error += loss\n",
    "                  optimizer.zero_grad()\n",
    "                  loss.backward()\n",
    "                  optimizer.step()\n",
    "                  # Unmask the masked gradients after backpropagation\n",
    "                  torch.set_grad_enabled(True)\n",
    "            \n",
    "            print(f\"Training Error: {error:.2f}\\tCurrent Iteration {i}/{self.epochs}\")\n",
    "            errors.append(float(error))\n",
    "            error = 0.0\n",
    "        return errors\n",
    "       \n",
    "    def evaluate(self, mode:str=\"validation\") -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the AutoRec - model.\n",
    "        \n",
    "        Params:\n",
    "            mode (str, optional): A string representing the dataset (validation, test) on which to evaluate on.\n",
    "        \n",
    "        Returns:\n",
    "            float: A number that represents the test - error of the AutoRec-model on the test set. In the case of the\n",
    "            'Conviction' task it is the mean - accuracy error. In the case of the 'Weight' task it is the RMSE.\n",
    "        \"\"\"\n",
    "        \n",
    "        trues, preds = [], []\n",
    "        # Set model into evaluation mode\n",
    "        self.eval = True\n",
    "\n",
    "        if mode == \"validation\":\n",
    "            test_user_mapping = self.rmh.create_test_user_mapping(self.rmh.train_rating_matrix, self.rmh.validation_rating_matrix)\n",
    "            if self.task == \"Conviction\":\n",
    "                test_eval_indices_conviction = {user:items[items % 2 == 1] for user,items in self.rmh.validation_eval_indices.items()}\n",
    "                # To match the indices of the training, integer divide all odd indices by 2 to map them to the correct index\n",
    "                for key, value in test_eval_indices_conviction.items():\n",
    "                    test_eval_indices_conviction[key] = value // 2\n",
    "                # Get rid of the username column in the test-rating -matrix for converting only numerical values into a pytorch tensor\n",
    "                test_rating_matrix_copy = self.rmh.validation_rating_matrix.drop([\"username\"], axis=1)\n",
    "                # Trim the original validation rating_matrix to the conviction columns only\n",
    "                trimmed_test_rating_matrix = torch.index_select(torch.from_numpy(test_rating_matrix_copy.values).to(torch.float16), 1, torch.arange(1, test_rating_matrix_copy.shape[1], 2))\n",
    "            elif self.task == \"Weight\":\n",
    "                test_eval_indices_weight = {user:items[items % 2 == 0] for user,items in self.rmh.validation_eval_indices.items()}\n",
    "                # To match the indices of the training, integer divide all odd indices by 2 to map them to the correct index\n",
    "                for key, value in test_eval_indices_weight.items():\n",
    "                    test_eval_indices_weight[key] = value // 2\n",
    "                # Get rid of the username column in the test-rating -matrix for converting only numerical values into a pytorch tensor\n",
    "                test_rating_matrix_copy = self.rmh.validation_rating_matrix.drop([\"username\"], axis=1)\n",
    "                # Trim the original test_rating_matrix to the conviction columns only\n",
    "                trimmed_test_rating_matrix = torch.index_select(torch.from_numpy(test_rating_matrix_copy.values).to(torch.float16), 1, torch.arange(0, test_rating_matrix_copy.shape[1], 2))\n",
    "\n",
    "        else:\n",
    "            # Calculate position of test user in train input vector \n",
    "            test_user_mapping = self.rmh.create_test_user_mapping(self.rmh.train_rating_matrix, self.rmh.test_rating_matrix)\n",
    "            if self.task == \"Conviction\":\n",
    "                test_eval_indices_conviction = {user:items[items % 2 == 1] for user,items in self.rmh.test_eval_indices.items()}\n",
    "                # To match the indices of the training, integer divide all odd indices by 2 to map them to the correct index\n",
    "                for key, value in test_eval_indices_conviction.items():\n",
    "                    test_eval_indices_conviction[key] = value // 2\n",
    "                # Get rid of the username column in the test-rating -matrix for converting only numerical values into a pytorch tensor\n",
    "                test_rating_matrix_copy = self.rmh.test_rating_matrix.drop([\"username\"], axis=1)\n",
    "                # Trim the original test_rating_matrix to the conviction columns only\n",
    "                trimmed_test_rating_matrix = torch.index_select(torch.from_numpy(test_rating_matrix_copy.values).to(torch.float16), 1, torch.arange(1, test_rating_matrix_copy.shape[1], 2))\n",
    "            elif self.task == \"Weight\":\n",
    "                test_eval_indices_weight = {user:items[items % 2 == 0] for user,items in self.rmh.test_eval_indices.items()}\n",
    "                # To match the indices of the training, integer divide all odd indices by 2 to map them to the correct index\n",
    "                for key, value in test_eval_indices_weight.items():\n",
    "                    test_eval_indices_weight[key] = value // 2\n",
    "                # Get rid of the username column in the test-rating -matrix for converting only numerical values into a pytorch tensor\n",
    "                test_rating_matrix_copy = self.rmh.test_rating_matrix.drop([\"username\"], axis=1)\n",
    "                # Trim the original test_rating_matrix to the conviction columns only\n",
    "                trimmed_test_rating_matrix = torch.index_select(torch.from_numpy(test_rating_matrix_copy.values).to(torch.float16), 1, torch.arange(0, test_rating_matrix_copy.shape[1], 2))\n",
    "\n",
    "        if self.task == \"Conviction\":\n",
    "            mean_acc = 0.0\n",
    "            # Variable for counting the correct 0/1 prediction\n",
    "            count_equality = 0\n",
    "            for username, test_samples in test_eval_indices_conviction.items():\n",
    "                for arg_idx in test_samples:\n",
    "                    # Look up true value\n",
    "                    true_value = int(trimmed_test_rating_matrix[username[1]][arg_idx])\n",
    "                    # Get prediction for the row in which the test user is located in the training set\n",
    "                    prediction = int(torch.round(self.forward(self.X[:,arg_idx])[test_user_mapping[username[0]]]))\n",
    "                    trues.append(int(true_value))\n",
    "                    preds.append(int(prediction))\n",
    "                    # If the prediction is correct, increment the counter\n",
    "                    if  true_value == prediction:\n",
    "                        count_equality += 1\n",
    "                # Normalize by the number of test samples for this user\n",
    "                mean_acc += count_equality / len(test_samples)\n",
    "                # Set the count equality to 0 for the next user\n",
    "                count_equality = 0\n",
    "            # Normalize the error by the number of users in the test-set\n",
    "            mean_acc /= len(test_eval_indices_conviction)\n",
    "            print(f\"Accuracy: {mean_acc:.3f}\")\n",
    "            return np.array(trues), np.array(preds)\n",
    "        \n",
    "        else: \n",
    "            # Calculate the averaged root mean squared error for the Prediction of Weight (PoW) - task\n",
    "            rmse_error = 0.0\n",
    "            # Variable for measuring the distance of the true value and the prediction\n",
    "            prediction_distance = 0.0\n",
    "            for username, test_samples in test_eval_indices_weight.items():\n",
    "                for arg_idx in test_samples:\n",
    "                    # Look up the true value\n",
    "                    true_value = trimmed_test_rating_matrix[username[1]][arg_idx]\n",
    "                    prediction = torch.round((self.forward(self.X[:,arg_idx])[test_user_mapping[username[0]]]))\n",
    "                    trues.append(int(true_value))\n",
    "                    preds.append(int(prediction))\n",
    "                    prediction_distance += float(torch.pow(true_value - prediction, 2))\n",
    "                # Normalize by the number of test samples for this user     \n",
    "                rmse_error += (prediction_distance / len(test_samples))\n",
    "                # Set the prediction distance to 0 for the next user\n",
    "                prediction_distance = 0\n",
    "            # Normalize the prediction_distance by the number of users in the test-set\n",
    "            rmse_error /= len(test_eval_indices_weight)\n",
    "            print(f\"RMSE: {rmse_error:.3f}\")\n",
    "            \n",
    "            return np.array(trues), np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autorec = AutoRec(**i_autorec_config)\n",
    "results = autorec.train()\n",
    "graphics.plot_training_error(error=results, title=\"AutoRec Objective function error\", xlabel=\"Iterations\", ylabel=\"Error\")\n",
    "trues, preds = autorec.evaluate(\"test\")\n",
    "\n",
    "%run MetricHelper.ipynb\n",
    "print(mh.compute_average_metrics())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c4321509887871942225181aea45e229e5aed2157cb28edcc519edea6ae29dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('ba_thesis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
