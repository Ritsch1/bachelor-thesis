{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=\"jupyter nbconvert --output-dir='../python-code' --to python AutoRec.ipynb --TemplateExporter.exclude_markdown=True --TemplateExporter.exclude_input_prompt=True\", returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export notebook as python script to the ../python-code folder\n",
    "subprocess.run(\"jupyter nbconvert --output-dir='../python-code' --to python AutoRec.ipynb --TemplateExporter.exclude_markdown=True --TemplateExporter.exclude_input_prompt=True\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRec(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the AutoRec autoencoder model.\n",
    "    \"\"\"    \n",
    "    def __init__(self, input_dim:int, hidden_layer_dim:int, mask_value:int, learning_rate:float, \n",
    "                 epochs:int, rmh, task:str=\"Conviction\", random_seed:int=42, pool_mode:bool=False):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "            input_dim (int): The input dimension of the user or item vector.\n",
    "            hidden_layer_dim (int): The size of neurons in the hidden layer. \n",
    "            mask_value (int): The value that is used for masking missing values in the input.\n",
    "            learning_rate (float): The learning rate that is initially used to update the weights of the network.\n",
    "            epochs (int): The number of times the data passes through the network in training.\n",
    "            task (str, optional): The task that the AutoRec model is trained on, can be \"Conviction\" or \"Weight\". Defaults to \"Conviction\".\n",
    "            random_seed (int, optional): The value that is used to set the random state of the model. Important for reproducing the results. Defaults to 42.\n",
    "            pool_mode (bool, optional): Flag that decides if one dedicated model shall be built for each item. Defaults to False.\n",
    "        \"\"\"\n",
    "        super(AutoRec, self).__init__()\n",
    "        \n",
    "        # Variables to perform assertions on\n",
    "        checklist = [input_dim, hidden_layer_dim, epochs]\n",
    "        assert all([v > 0 for v in checklist + [learning_rate]]) & all([type(v) == int for v in checklist]), \\\n",
    "        \"Input dimension, epochs and hidden layer dimension need to be positive integers.\"\n",
    "        \n",
    "        # Initialize GPU for computation if available\n",
    "        machine = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.device = torch.device(machine)\n",
    "        \n",
    "        self.pool_mode = pool_mode\n",
    "        self.random_seed = random_seed\n",
    "        torch.manual_seed(self.random_seed)\n",
    "        random.seed(self.random_seed)\n",
    "        np.random.seed(self.random_seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.cuda.manual_seed(self.random_seed)\n",
    "        torch.cuda.manual_seed_all(self.random_seed)\n",
    "        \n",
    "        self.mask_value = mask_value\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        # Creating linear layers\n",
    "        self.inputLayer = torch.nn.Linear(input_dim, hidden_layer_dim, bias=True, device=self.device,)\n",
    "        # input dimension equals output dimensions in autoencoders\n",
    "        self.outputLayer = torch.nn.Linear(hidden_layer_dim, input_dim, bias=True, device=self.device)\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs \n",
    "        self.rmh = rmh\n",
    "        self.task = task\n",
    "        build_rating_matrix()\n",
    "        # Build as many dedicated autorec models as there are items\n",
    "        if self.pool_mode:\n",
    "            self.models = []\n",
    "            for m in range(self.X.shape[1]):\n",
    "                self.models.append(AutoRec(self.input_dim, hidden_layer_dim, self.mask_value, self.learning_rate, self.epochs, rmh, self.task, self.random_seed, pool_mode=False))\n",
    "       \n",
    "    def build_rating_matrix(self) -> None:\n",
    "        self.X = torch.nan_to_num(self.rmh.final_rating_matrix, nan=self.mask_value)\n",
    "        # Slice the rating matrix based on the task\n",
    "        self.X = self.X[:,1::2].to(self.device) if self.task == \"Conviction\" else self.X[:,::2].to(self.device)\n",
    "        self.X = self.X.type(torch.FloatTensor)   \n",
    "     \n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate a reconstruction of the input tensor.\n",
    "\n",
    "        Params:\n",
    "            x (torch.Tensor): Masked user or item - vector.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Reconstruction of the masked user or item - vector.\n",
    "        \"\"\"\n",
    "        sigmoid = torch.nn.Sigmoid()\n",
    "        identity = torch.nn.Identity()\n",
    "        hidden_layer_result = sigmoid(self.inputLayer(x))\n",
    "        x_reconstruction = self.outputLayer(hidden_layer_result)\n",
    "        # Mask the gradient during training\n",
    "        if self.training:\n",
    "            masked_positions = (x == self.mask_value)\n",
    "            for i, mask in enumerate(masked_positions):\n",
    "                if mask:\n",
    "                    self.inputLayer.weight[0][i].detach() \n",
    "                    self.inputLayer.weight[1][i].detach() \n",
    "            \n",
    "        return x_reconstruction\n",
    "    \n",
    "    def train(self) -> list:\n",
    "        \"\"\"\n",
    "        Train the AutoRec model.\n",
    "\n",
    "        Params:\n",
    "            X (torch.Tensor): The masked training dataset consisting of item or user vectors.\n",
    "        Returns:\n",
    "            List of error values for each iteration.\n",
    "        \"\"\"\n",
    "        error = 0.0\n",
    "        errors = []\n",
    "        optimizer = torch.optim.Adam(self.parameters(), self.learning_rate)\n",
    "        i = 0\n",
    "        while i < self.epochs:\n",
    "            i += 1\n",
    "            for x in self.X.T:\n",
    "                x_reconstruction = self.forward(x)\n",
    "                \n",
    "                idx_non_masked_entries = torch.where(~(x == self.mask_value))[0]\n",
    "                num_non_masked_entries = len(idx_non_masked_entries)\n",
    "                # If there are some items without ratings, skip them\n",
    "                if num_non_masked_entries == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    loss = torch.div(torch.sum(torch.pow((x[idx_non_masked_entries] - x_reconstruction[idx_non_masked_entries]), 2)), num_non_masked_entries) \n",
    "                    error += loss\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    # Unmask the masked gradients after backpropagation\n",
    "                    torch.set_grad_enabled(True)\n",
    "            \n",
    "            print(f\"Validation error: {self.evaluate()}\")\n",
    "            self.train = True\n",
    "            print(f\"Iteration {i}/{self.epochs} - Error: {error:.2f}\")\n",
    "            errors.append(float(error))\n",
    "            error = 0.0\n",
    "        return errors\n",
    "\n",
    "    def evaluate(self, mode:str=\"validation\") -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the AutoRec - model.\n",
    "\n",
    "        Returns:\n",
    "        float: A number that represents the test - error of the AutoRec-model on the test set. In the case of the\n",
    "        'Conviction' task it is the mean - accuracy error. In the case of the 'Weight' task it is the RMSE.\n",
    "        \"\"\"\n",
    "        # Set model into evaluation mode\n",
    "        self.eval = True\n",
    "\n",
    "        if mode == \"validation\":\n",
    "            test_user_mapping = self.rmh.create_test_user_mapping(self.rmh.train_rating_matrix, self.rmh.validation_rating_matrix)\n",
    "            if self.task == \"Conviction\":\n",
    "                test_eval_indices_conviction = {user:items[items % 2 == 1] for user,items in self.rmh.validation_eval_indices.items()}\n",
    "                # To match the indices of the training, integer divide all odd indices by 2 to map them to the correct index\n",
    "                for key, value in test_eval_indices_conviction.items():\n",
    "                    test_eval_indices_conviction[key] = value // 2\n",
    "                # Get rid of the username column in the test-rating -matrix for converting only numerical values into a pytorch tensor\n",
    "                test_rating_matrix_copy = self.rmh.validation_rating_matrix.drop([\"username\"], axis=1)\n",
    "                # Trim the original validation rating_matrix to the conviction columns only\n",
    "                trimmed_test_rating_matrix = torch.index_select(torch.from_numpy(test_rating_matrix_copy.values).to(torch.float16), 1, torch.arange(1, test_rating_matrix_copy.shape[1], 2))\n",
    "            elif self.task == \"Weight\":\n",
    "                test_eval_indices_weight = {user:items[items % 2 == 0] for user,items in self.rmh.validation_eval_indices.items()}\n",
    "                # To match the indices of the training, integer divide all odd indices by 2 to map them to the correct index\n",
    "                for key, value in test_eval_indices_weight.items():\n",
    "                    test_eval_indices_weight[key] = value // 2\n",
    "                # Get rid of the username column in the test-rating -matrix for converting only numerical values into a pytorch tensor\n",
    "                test_rating_matrix_copy = self.rmh.validation_rating_matrix.drop([\"username\"], axis=1)\n",
    "                # Trim the original test_rating_matrix to the conviction columns only\n",
    "                trimmed_test_rating_matrix = torch.index_select(torch.from_numpy(test_rating_matrix_copy.values).to(torch.float16), 1, torch.arange(0, test_rating_matrix_copy.shape[1], 2))\n",
    "\n",
    "        else:\n",
    "            # Calculate position of test user in train input vector \n",
    "            test_user_mapping = self.rmh.create_test_user_mapping(self.rmh.train_rating_matrix, self.rmh.test_rating_matrix)\n",
    "            if self.task == \"Conviction\":\n",
    "                test_eval_indices_conviction = {user:items[items % 2 == 1] for user,items in self.rmh.test_eval_indices.items()}\n",
    "                # To match the indices of the training, integer divide all odd indices by 2 to map them to the correct index\n",
    "                for key, value in test_eval_indices_conviction.items():\n",
    "                    test_eval_indices_conviction[key] = value // 2\n",
    "                # Get rid of the username column in the test-rating -matrix for converting only numerical values into a pytorch tensor\n",
    "                test_rating_matrix_copy = self.rmh.test_rating_matrix.drop([\"username\"], axis=1)\n",
    "                # Trim the original test_rating_matrix to the conviction columns only\n",
    "                trimmed_test_rating_matrix = torch.index_select(torch.from_numpy(test_rating_matrix_copy.values).to(torch.float16), 1, torch.arange(1, test_rating_matrix_copy.shape[1], 2))\n",
    "            elif self.task == \"Weight\":\n",
    "                test_eval_indices_weight = {user:items[items % 2 == 0] for user,items in self.rmh.test_eval_indices.items()}\n",
    "                # To match the indices of the training, integer divide all odd indices by 2 to map them to the correct index\n",
    "                for key, value in test_eval_indices_weight.items():\n",
    "                    test_eval_indices_weight[key] = value // 2\n",
    "                # Get rid of the username column in the test-rating -matrix for converting only numerical values into a pytorch tensor\n",
    "                test_rating_matrix_copy = self.rmh.test_rating_matrix.drop([\"username\"], axis=1)\n",
    "                # Trim the original test_rating_matrix to the conviction columns only\n",
    "                trimmed_test_rating_matrix = torch.index_select(torch.from_numpy(test_rating_matrix_copy.values).to(torch.float16), 1, torch.arange(0, test_rating_matrix_copy.shape[1], 2))\n",
    "\n",
    "        if self.task == \"Conviction\":\n",
    "            mean_acc = 0.0\n",
    "            # Variable for counting the correct 0/1 prediction\n",
    "            count_equality = 0\n",
    "            for username, test_samples in test_eval_indices_conviction.items():\n",
    "                for arg_idx in test_samples:\n",
    "                    # Look up true value\n",
    "                    true_value = int(trimmed_test_rating_matrix[username[1]][arg_idx])\n",
    "                    # Get prediction for the row in which the test user is located in the training set\n",
    "                    prediction = int(torch.round(self.forward(self.X[:,arg_idx])[test_user_mapping[username[0]]]))\n",
    "                    # If the prediction is correct, increment the counter\n",
    "                    if  true_value == prediction:\n",
    "                        count_equality += 1\n",
    "                # Normalize by the number of test samples for this user\n",
    "                mean_acc += count_equality / len(test_samples)\n",
    "                # Set the count equality to 0 for the next user\n",
    "                count_equality = 0\n",
    "            # Normalize the error by the number of users in the test-set\n",
    "            mean_acc /= len(test_eval_indices_conviction)\n",
    "        \n",
    "            return mean_acc\n",
    "        \n",
    "        else: \n",
    "            # Calculate the averaged root mean squared error for the Prediction of Weight (PoW) - task\n",
    "            rmse_error = 0.0\n",
    "            # Variable for measuring the distance of the true value and the prediction\n",
    "            prediction_distance = 0.0\n",
    "            for username, test_samples in test_eval_indices_weight.items():\n",
    "                for arg_idx in test_samples:\n",
    "                    # Look up the true value\n",
    "                    true_value = trimmed_test_rating_matrix[username[1]][arg_idx]\n",
    "                    prediction = torch.round(torch.abs((self.forward(self.X[:,arg_idx])[test_user_mapping[username[0]]])))\n",
    "                    prediction_distance += float(torch.pow(true_value - prediction, 2))\n",
    "                # Normalize by the number of test samples for this user     \n",
    "                rmse_error += (prediction_distance / len(test_samples))\n",
    "                # Set the prediction distance to 0 for the next user\n",
    "                prediction_distance = 0\n",
    "            # Normalize the prediction_distance by the number of users in the test-set\n",
    "            rmse_error /= len(test_eval_indices_weight)\n",
    "            \n",
    "            return rmse_error\n",
    "                    \n",
    "    def plot_training_error(self, error:[float], **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        Plots the training error for every training iteration.\n",
    "        \n",
    "        Params:\n",
    "            error (list): A list of error - values that correspond to each training iteration of the AutoRec - model.    \n",
    "            **kwargs: Arbitrary many keyword arguments to customize the plot. E.g. color, linewidth or title.\n",
    "        \"\"\" \n",
    "        plt.plot([i for i in range(1, len(error)+1)], error)\n",
    "        for k in kwargs.keys():\n",
    "            # Invoke the function k of the plt - module to customize the plot\n",
    "            getattr(plt, k) (kwargs[k])\n",
    "        \n",
    "        plt.show()                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for executing the Rating-Matrix-Handler notebook\n",
    "timepoint = \"T1_T2\"\n",
    "train_path = f\"../../data/{timepoint}/train.csv\"\n",
    "test_path  = f\"../../data/{timepoint}/test.csv\"\n",
    "validation_path = f\"../../data/{timepoint}/validation.csv\"\n",
    "%run Rating_Matrix_Handler.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'final_rating_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4088/1203083056.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mautorec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoRec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrmh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_rating_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Conviction\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mautorec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4088/2224050595.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dim, hidden_layer_dim, mask_value, learning_rate, epochs, rmh, task, random_seed, pool_mode)\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAutoRec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_layer_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmask_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4088/2224050595.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dim, hidden_layer_dim, mask_value, learning_rate, epochs, rmh, task, random_seed, pool_mode)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_rating_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmask_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;31m# Slice the rating matrix based on the task\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"Conviction\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'final_rating_matrix'"
     ]
    }
   ],
   "source": [
    "autorec = AutoRec(rmh.train_rating_matrix.shape[0], 10, -1, 0.001, 20, rmh, task=\"Conviction\", random_seed=500, pool_mode=True)\n",
    "autorec.models"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c4321509887871942225181aea45e229e5aed2157cb28edcc519edea6ae29dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('ba_thesis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
