{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# imports\r\n",
    "import papermill as pm\r\n",
    "import ipywidgets as widgets\r\n",
    "from ipywidgets.widgets import interact\r\n",
    "import subprocess"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "@interact(dataset=[(\"T1_T2\", \"T1_T2\"), (\"T2_T3\", \"T2_T3\")])\r\n",
    "def set_prediction_dataset(dataset:str=\"T1_T2\") -> str:\r\n",
    "    \"\"\"\r\n",
    "    Setting the dataset to be trained and evaluated on with a dropdown.\r\n",
    "\r\n",
    "    Parmas:\r\n",
    "        dataset (str, optional): Dataset to be trained and evaluated on. Defaults to \"T1_T2\".\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        str: Dataset to be trained and evaluated on.\r\n",
    "    \"\"\"\r\n",
    "    return dataset"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "927287825fcd4c04add209660c44156c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset', options=(('T1_T2', 'T1_T2'), ('T2_T3', 'T2_T3')), value=…"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "prediction_goal = set_prediction_dataset()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Export notebook as python script to the ../python-code - folder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "subprocess.run(\"jupyter nbconvert --output-dir='../python-code' --to python Main.ipynb --TemplateExporter.exclude_markdown=True --TemplateExporter.exclude_input_prompt=True\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CompletedProcess(args=\"jupyter nbconvert --output-dir='../python-code' --to python Main.ipynb --TemplateExporter.exclude_markdown=True --TemplateExporter.exclude_input_prompt=True\", returncode=0)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run the complete TLMF - algorithm\n",
    "\n",
    "#### 1. Run the WTMF - notebook to compute the argument similarity matrix for the TLMF-algorithm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Parameters for executing the WTMF algorithm\r\n",
    "params = {\"k\":50, \"gamma\":0.05, \"weight\":0.05, \"training_iterations\":50, \"random_seed\":1, \"print_frequency\":1}\r\n",
    "# Execute a parametrized version of the WTMF notebook\r\n",
    "pm.execute_notebook(\"WTMF.ipynb\", \"WTMF.ipynb\", params)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Run the Rating-Matrix-Handler notebook to prepare the rating-matrix for the TLMF-algorithm."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Parameters for executing the Rating-Matrix-Handler notebook\r\n",
    "params = {\"train_path\": \"C:\\\\Users\\\\Rico\\\\Desktop\\\\Diverses\\\\bachelorarbeit\\\\bachelor-thesis\\\\data\\\\T1_T2\\\\train.csv\",\r\n",
    "          \"test_path\" : \"C:\\\\Users\\\\Rico\\\\Desktop\\\\Diverses\\\\bachelorarbeit\\\\bachelor-thesis\\\\data\\\\T1_T2\\\\test.csv\"}\r\n",
    "# Execute a parametrized version of the Rating-Matrix-Handler notebook\r\n",
    "pm.execute_notebook(\"Rating_Matrix_Handler.ipynb\", \"Rating_Matrix_Handler.ipynb\", params, log_output=False, report_mode=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Executing: 100%|██████████| 7/7 [00:07<00:00,  1.08s/cell]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'code',\n",
       "   'execution_count': 1,\n",
       "   'id': '22035808',\n",
       "   'metadata': {'execution': {'iopub.execute_input': '2021-09-03T20:50:51.639365Z',\n",
       "     'iopub.status.busy': '2021-09-03T20:50:51.636354Z',\n",
       "     'iopub.status.idle': '2021-09-03T20:50:52.929974Z',\n",
       "     'shell.execute_reply': '2021-09-03T20:50:52.929974Z'},\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2021-09-03T20:50:51.586363',\n",
       "     'end_time': '2021-09-03T20:50:52.930982',\n",
       "     'duration': 1.344619,\n",
       "     'status': 'completed'},\n",
       "    'tags': []},\n",
       "   'outputs': [],\n",
       "   'source': '# imports\\nimport pandas as pd\\nimport numpy as np\\nfrom IPython.core.debugger import set_trace\\nimport torch\\nfrom collections import namedtuple'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'id': '6c1ac9e0',\n",
       "   'metadata': {'papermill': {'exception': False,\n",
       "     'start_time': '2021-09-03T20:50:52.937957',\n",
       "     'end_time': '2021-09-03T20:50:52.946961',\n",
       "     'duration': 0.009004,\n",
       "     'status': 'completed'},\n",
       "    'tags': []},\n",
       "   'source': '# Export notebook as python script to the ../python-code - folder'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 2,\n",
       "   'id': 'c6949ab9',\n",
       "   'metadata': {'execution': {'iopub.execute_input': '2021-09-03T20:50:52.967959Z',\n",
       "     'iopub.status.busy': '2021-09-03T20:50:52.966956Z',\n",
       "     'iopub.status.idle': '2021-09-03T20:50:55.572433Z',\n",
       "     'shell.execute_reply': '2021-09-03T20:50:55.571454Z'},\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2021-09-03T20:50:52.952953',\n",
       "     'end_time': '2021-09-03T20:50:55.573433',\n",
       "     'duration': 2.62048,\n",
       "     'status': 'completed'},\n",
       "    'tags': []},\n",
       "   'outputs': [{'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': '[NbConvertApp] Converting notebook Rating_Matrix_Handler.ipynb to python\\n[NbConvertApp] Writing 5322 bytes to ..\\\\python-code\\\\Rating_Matrix_Handler.py\\n'}],\n",
       "   'source': '!jupyter nbconvert --output-dir=\"../python-code\" --to python Rating_Matrix_Handler.ipynb --TemplateExporter.exclude_markdown=True --TemplateExporter.exclude_input_prompt=True'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'id': '2fcebc4d',\n",
       "   'metadata': {'papermill': {'exception': False,\n",
       "     'start_time': '2021-09-03T20:50:55.582454',\n",
       "     'end_time': '2021-09-03T20:50:55.591430',\n",
       "     'duration': 0.008976,\n",
       "     'status': 'completed'},\n",
       "    'tags': []},\n",
       "   'source': '# Rating - Matrix - Handler'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 3,\n",
       "   'id': '80ab2c89',\n",
       "   'metadata': {'execution': {'iopub.execute_input': '2021-09-03T20:50:55.628433Z',\n",
       "     'iopub.status.busy': '2021-09-03T20:50:55.627434Z',\n",
       "     'iopub.status.idle': '2021-09-03T20:50:55.633433Z',\n",
       "     'shell.execute_reply': '2021-09-03T20:50:55.633433Z'},\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2021-09-03T20:50:55.597453',\n",
       "     'end_time': '2021-09-03T20:50:55.633433',\n",
       "     'duration': 0.03598,\n",
       "     'status': 'completed'},\n",
       "    'tags': ['parameters']},\n",
       "   'outputs': [],\n",
       "   'source': 'class Rating_Matrix_Handler():\\r\\n    \"\"\"\\r\\n    A class that deals with all Rating-Matrix related issues like merging and masking rating-matrices.\\r\\n    \"\"\"\\r\\n    \\r\\n    def __init__(self, train_rating_matrix:pd.DataFrame, test_rating_matrix:pd.DataFrame, validation_rating_matrix:pd.DataFrame=None):\\r\\n        \"\"\"\\r\\n        Params:\\r\\n            train_rating_matrix (pd.DataFrame): The training rating_matrix on which the TLMF algorithm will be trained upon.\\r\\n            validation_rating_matrix (pd.DataFrame): The validation rating_matrix on which the TLMF algorithm can be validated on.\\r\\n            test_rating_matrix (pd.DataFrame): The test rating_matrix on which the TLMF algorithm will be tested upon.\\r\\n        \"\"\"\\r\\n        self.train_rating_matrix = train_rating_matrix\\r\\n        self.validation_rating_matrix = validation_rating_matrix\\r\\n        self.is_validation_set_available = self.validation_rating_matrix is not None \\r\\n        self.test_rating_matrix = test_rating_matrix\\r\\n        self.validation_eval_indices = None\\r\\n        self.test_eval_indices = None\\r\\n        # Initialize GPU for computation if available            \\r\\n        machine = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\\r\\n        self.device = torch.device(machine)\\r\\n        \\r\\n    def merge_rating_matrices(self, dim:int=1, mode:str=\"Test\") -> None:\\r\\n        \"\"\"\\r\\n        Left-joins the training rating-matrix together on identical users with either the test-matrix or the validation-matrix(depending on the value of mode).\\r\\n\\r\\n        Params:\\r\\n            dim (int, optional): The dimension along which rating matrices are merged. Defaults to 1.\\r\\n            mode (str, optional): The mode of df2. It can either be \"Test\" or \"Validation\". Defaults to \"Test\".\\r\\n        \"\"\"\\r\\n        # Assertions\\r\\n        assert dim >= 0, \"Dimension must be non-negative.\"\\r\\n        \\r\\n        if mode==\"Test\":    \\r\\n            df = self.test_rating_matrix\\r\\n            self.test_eval_indices = self.get_eval_indices(df)\\r\\n        elif mode==\"Validation\":\\r\\n            df = self.validation_rating_matrix\\r\\n            self.validation_eval_indices = self.get_eval_indices(df)\\r\\n            \\r\\n        # Get all non-na column indices for each username.\\r\\n        eval_indices = self.get_eval_indices(df)\\r\\n        # Join the matrices on the username column, keep all usernames that were already in the training matrix. Replace all values of the joined table with NaN as they have to be predicted later.\\r\\n        df_nan = df.copy()\\r\\n        df_nan.loc[:, df_nan.columns != \"username\"] = np.nan\\r\\n        self.final_rating_matrix = self.train_rating_matrix.copy() \\r\\n        self.final_rating_matrix = self.final_rating_matrix.merge(right=df_nan, how=\"left\", on=\"username\")\\r\\n        # Drop the username column as it is non-numeric and can\\'t be converted to a tensor.\\r\\n        self.final_rating_matrix.drop(labels=[\"username\"], axis=1, inplace=True)\\r\\n        # The same for the joined matrix as the username column contains non-na values but will not be evaluated.\\r\\n        df.drop(labels=[\"username\"], axis=1, inplace=True)\\r\\n        # Set the datatypes of the rating matrix to float16 to save memory and speed up computation while keeping the nan-values (not possible for integer datatype). \\r\\n        self.final_rating_matrix = torch.from_numpy(self.final_rating_matrix.values).to(torch.float16).to(self.device)\\r\\n        \\r\\n    def get_eval_indices(self, df:pd.DataFrame, mode:str=\"Test\") -> dict:\\r\\n        \"\"\"\\r\\n        Get all indices that are not NaN of the provided dataframe. These indices are later used to evaluate recommender systems on.\\r\\n\\r\\n        Params:\\r\\n            df (pd.DataFrame): Dataframe whose non-null indices have to be found.\\r\\n        Returns:\\r\\n            dict: A dictionary containg a username as key associated with a numpy-array containing all the indices of the non-na columns for that username.\\r\\n        \"\"\"        \\r\\n        # Get all not-null indices from the dataframe\\r\\n        mask_idxs = np.argwhere(~pd.isna(df.values))\\r\\n        # Perform a group by on the username - row - index.\\r\\n        unique_username_rows = np.unique(mask_idxs[:,0], return_index=True)[1][1:]\\r\\n        mask_idxs_grouped = np.split(mask_idxs[:,1], unique_username_rows)\\r\\n        # Combine the row indices with all the non - na column - indices for this row\\r\\n        username_column_agg = np.array(list(zip(list(df[\"username\"]), mask_idxs_grouped)), dtype=object)\\r\\n        # Exclude the username column from the non - na values, which is the first one\\r\\n        username_column_agg = {a[0]: a[1][1:]-1 for a in username_column_agg}\\r\\n        return username_column_agg'},\n",
       "  {'id': '6cc46907',\n",
       "   'cell_type': 'code',\n",
       "   'metadata': {'tags': ['injected-parameters'],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2021-09-03T20:50:55.642433',\n",
       "     'end_time': '2021-09-03T20:50:55.664904',\n",
       "     'duration': 0.022471,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2021-09-03T20:50:55.653432Z',\n",
       "     'iopub.execute_input': '2021-09-03T20:50:55.653432Z',\n",
       "     'shell.execute_reply': '2021-09-03T20:50:55.663886Z',\n",
       "     'iopub.status.idle': '2021-09-03T20:50:55.664904Z'}},\n",
       "   'execution_count': 4,\n",
       "   'source': '# Parameters\\ntrain_path = \"C:\\\\\\\\Users\\\\\\\\Rico\\\\\\\\Desktop\\\\\\\\Diverses\\\\\\\\bachelorarbeit\\\\\\\\bachelor-thesis\\\\\\\\data\\\\\\\\T1_T2\\\\\\\\train.csv\"\\ntest_path = \"C:\\\\\\\\Users\\\\\\\\Rico\\\\\\\\Desktop\\\\\\\\Diverses\\\\\\\\bachelorarbeit\\\\\\\\bachelor-thesis\\\\\\\\data\\\\\\\\T1_T2\\\\\\\\test.csv\"\\n',\n",
       "   'outputs': []},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 5,\n",
       "   'id': 'a285ffa9',\n",
       "   'metadata': {'execution': {'iopub.execute_input': '2021-09-03T20:50:55.685932Z',\n",
       "     'iopub.status.busy': '2021-09-03T20:50:55.684919Z',\n",
       "     'iopub.status.idle': '2021-09-03T20:50:55.885919Z',\n",
       "     'shell.execute_reply': '2021-09-03T20:50:55.884920Z'},\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2021-09-03T20:50:55.671908',\n",
       "     'end_time': '2021-09-03T20:50:55.885919',\n",
       "     'duration': 0.214011,\n",
       "     'status': 'completed'},\n",
       "    'tags': []},\n",
       "   'outputs': [],\n",
       "   'source': 'train = pd.read_csv(train_path)\\r\\ntest = pd.read_csv(test_path)\\r\\nrmh = Rating_Matrix_Handler(train_rating_matrix=train, test_rating_matrix=test)\\r\\nrmh.merge_rating_matrices()'}],\n",
       " 'metadata': {'celltoolbar': 'Tags',\n",
       "  'interpreter': {'hash': '9c4321509887871942225181aea45e229e5aed2157cb28edcc519edea6ae29dd'},\n",
       "  'kernelspec': {'display_name': 'Python 3 (ipykernel)',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'},\n",
       "  'language_info': {'name': 'python',\n",
       "   'version': '3.8.11',\n",
       "   'mimetype': 'text/x-python',\n",
       "   'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "   'pygments_lexer': 'ipython3',\n",
       "   'nbconvert_exporter': 'python',\n",
       "   'file_extension': '.py'},\n",
       "  'papermill': {'default_parameters': {},\n",
       "   'duration': 7.549367,\n",
       "   'end_time': '2021-09-03T20:50:56.444374',\n",
       "   'environment_variables': {},\n",
       "   'exception': None,\n",
       "   'input_path': 'Rating_Matrix_Handler.ipynb',\n",
       "   'output_path': 'Rating_Matrix_Handler.ipynb',\n",
       "   'parameters': {'train_path': 'C:\\\\Users\\\\Rico\\\\Desktop\\\\Diverses\\\\bachelorarbeit\\\\bachelor-thesis\\\\data\\\\T1_T2\\\\train.csv',\n",
       "    'test_path': 'C:\\\\Users\\\\Rico\\\\Desktop\\\\Diverses\\\\bachelorarbeit\\\\bachelor-thesis\\\\data\\\\T1_T2\\\\test.csv'},\n",
       "   'start_time': '2021-09-03T20:50:48.895007',\n",
       "   'version': '2.3.3'}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 5}"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Run the TLMF-notebook based on the calculated argument-similarity-matrix and the prepared argument-rating-matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Parameters for executing the Rating-Matrix-Handler notebook\r\n",
    "params = {\"wtmf\":wtmf, \"rmh\":rmh, \"d\":10, \"training_iterations\":50, \"random_seed\":1, \"print_frequency\":1, \"r\":0.05, \"l\":0.01, \"alpha\":0.2, \"n\":10}\r\n",
    "# Execute a parametrized version of the Rating-Matrix-Handler notebook\r\n",
    "pm.execute_notebook(\"TLMF.ipynb\", \"TLMF.ipynb\", params)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c4321509887871942225181aea45e229e5aed2157cb28edcc519edea6ae29dd"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('ba_thesis': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}