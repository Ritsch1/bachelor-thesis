{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets.widgets import interactive\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropdown for selecting the target time transitions of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = widgets.Dropdown(options=[(\"T1_T2\",\"T1_T2\"), (\"T2_T3\",\"T2_T3\")], description=\"Dataset\")\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropdown for selecting the target task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ = widgets.Dropdown(options=[(\"Conviction\",\"Conviction\"), (\"Weight\",\"Weight\")], description=\"Task\")\n",
    "display(task_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_goal = dataset.value\n",
    "task = task_.value\n",
    "# Metrics that should be evaluated on\n",
    "metrics = [\"precision\", \"recall\", \"f1\", \"gmean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in configuration file for setting best hyperparameter values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\", \"r\") as c:\n",
    "    config = json.loads(c.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare rating matrices for the different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for executing the Rating-Matrix-Handler notebook\n",
    "train_path = f\"../../data/{prediction_goal}/train.csv\"\n",
    "test_path  = f\"../../data/{prediction_goal}/test.csv\"\n",
    "validation_path = f\"../../data/{prediction_goal}/validation.csv\"\n",
    "%run Rating_Matrix_Handler.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Graphics notebook module for plotting functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Graphics.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the complete TLMF - algorithm\n",
    "\n",
    "#### 1. Run the WTMF - notebook to compute the argument similarity matrix for the TLMF-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtmf_config = config[\"hyperparameters\"][\"WTMF\"]\n",
    "%run WTMF.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Run the TLMF-notebook based on the calculated argument-similarity-matrix and the prepared argument-rating-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = wtmf.similarity_matrix\n",
    "tlmf_config = config[\"hyperparameters\"][\"TLMF\"][prediction_goal][task]\n",
    "%run TLMF.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the TLMF algorithm powered by the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run BERT.ipynb\n",
    "similarity_matrix = bert.similarity_matrix\n",
    "%run TLMF.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the complete I - AutoRec - algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_autorec_config = config[\"hyperparameters\"][\"AutoRec\"][prediction_goal][task]\n",
    "i_autorec_config[\"rmh\"] = rmh\n",
    "%run AutoRec.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the complete Naive Bayes - algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Naive_Bayes.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the complete User Neighborhood - algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_neighborhood_config = config[\"hyperparameters\"][\"User_Neighborhood\"][prediction_goal][task]\n",
    "%run User_Based_Neighborhood.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the majority voter (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Majority.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the NN algorithm (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parameters = config[\"hyperparameters\"][\"NN_Baseline\"][prediction_goal][task][\"data_parameters\"]\n",
    "%run NN_baseline.ipynb"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c4321509887871942225181aea45e229e5aed2157cb28edcc519edea6ae29dd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
